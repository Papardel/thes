{
  "bug_id": "6",
  "failed_tests": {
    "org.apache.commons.math3.optim.nonlinear.scalar.gradient.NonLinearConjugateGradientOptimizerTest": [
      {
        "methodName": "testTrivial",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testTrivial() {\n  LinearProblem problem\n  = new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n  NonLinearConjugateGradientOptimizer optimizer\n  = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n  new SimpleValueChecker(1e-6, 1e-6));\n  PointValuePair optimum\n  = optimizer.optimize(new MaxEval(100),\n  problem.getObjectiveFunction(),\n  problem.getObjectiveFunctionGradient(),\n  GoalType.MINIMIZE,\n  new InitialGuess(new double[] { 0 }));\n  Assert.assertEquals(1.5, optimum.getPoint()[0], 1.0e-10);\n  Assert.assertEquals(0.0, optimum.getValue(), 1.0e-10);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "NonLinearConjugateGradientOptimizerTest.testTrivial line 141"
        ]
      }
    ],
    "org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizerTest": [
      {
        "methodName": "testConstrainedRosen",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Rosen(), startPoint, insigma, boundaries,",
        "test_source": "  public void testConstrainedRosen() {\n  double[] startPoint = point(DIM, 0.1);\n  double[] insigma = point(DIM, 0.1);\n  double[][] boundaries = boundaries(DIM, -1, 2);\n  PointValuePair expected =\n  new PointValuePair(point(DIM,1.0),0.0);\n  doTest(new Rosen(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 2*LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  doTest(new Rosen(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 2*LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testConstrainedRosen line 348, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testElliRotated",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new ElliRotated(), startPoint, insigma, boundaries,",
        "test_source": "  public void testElliRotated() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new ElliRotated(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  doTest(new ElliRotated(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testElliRotated line 183, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testEllipse",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Elli(), startPoint, insigma, boundaries,",
        "test_source": "  public void testEllipse() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Elli(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  doTest(new Elli(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testEllipse line 168, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testTwoAxes",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new TwoAxes(), startPoint, insigma, boundaries,",
        "test_source": "  public void testTwoAxes() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new TwoAxes(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 2*LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 200000, expected);\n  doTest(new TwoAxes(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 2*LAMBDA, false, 0, 1e-13,\n  1e-8, 1e-3, 200000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testTwoAxes line 228, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testCigar",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Cigar(), startPoint, insigma, boundaries,",
        "test_source": "  public void testCigar() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Cigar(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 200000, expected);\n  doTest(new Cigar(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testCigar line 198, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testRosen",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Rosen(), startPoint, insigma, boundaries,",
        "test_source": "  public void testRosen() {\n  double[] startPoint = point(DIM,0.1);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,1.0),0.0);\n  doTest(new Rosen(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  doTest(new Rosen(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testRosen line 132, RetryRunner$1.evaluate line 67"
        ]
      },
      {
        "methodName": "testRastrigin",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Rastrigin(), startPoint, insigma, boundaries,",
        "test_source": "  public void testRastrigin() {\n  double[] startPoint = point(DIM,0.1);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Rastrigin(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, (int)(200*Math.sqrt(DIM)), true, 0, 1e-13,\n  1e-13, 1e-6, 200000, expected);\n  doTest(new Rastrigin(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, (int)(200*Math.sqrt(DIM)), false, 0, 1e-13,\n  1e-13, 1e-6, 200000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testRastrigin line 333, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testDiagonalRosen",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Rosen(), startPoint, insigma, boundaries,",
        "test_source": "  public void testDiagonalRosen() {\n  double[] startPoint = point(DIM,0.1);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,1.0),0.0);\n  doTest(new Rosen(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 1, 1e-13,\n  1e-10, 1e-4, 1000000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testDiagonalRosen line 363, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testSsDiffPow",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new SsDiffPow(), startPoint, insigma, boundaries,",
        "test_source": "  public void testSsDiffPow() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new SsDiffPow(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 10, true, 0, 1e-13,\n  1e-4, 1e-1, 200000, expected);\n  doTest(new SsDiffPow(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 10, false, 0, 1e-13,\n  1e-4, 1e-1, 200000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testSsDiffPow line 303, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testMaximize",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new MinusElli(), startPoint, insigma, boundaries,",
        "test_source": "  public void testMaximize() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),1.0);\n  doTest(new MinusElli(), startPoint, insigma, boundaries,\n  GoalType.MAXIMIZE, LAMBDA, true, 0, 1.0-1e-13,\n  2e-10, 5e-6, 100000, expected);\n  doTest(new MinusElli(), startPoint, insigma, boundaries,\n  GoalType.MAXIMIZE, LAMBDA, false, 0, 1.0-1e-13,\n  2e-10, 5e-6, 100000, expected);\n  boundaries = boundaries(DIM,-0.3,0.3); \n  startPoint = point(DIM,0.1);\n  doTest(new MinusElli(), startPoint, insigma, boundaries,\n  GoalType.MAXIMIZE, LAMBDA, true, 0, 1.0-1e-13,\n  2e-10, 5e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testMaximize line 148, RetryRunner$1.evaluate line 67"
        ]
      },
      {
        "methodName": "testAckley",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Ackley(), startPoint, insigma, boundaries,",
        "test_source": "  public void testAckley() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,1.0);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Ackley(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 2*LAMBDA, true, 0, 1e-13,\n  1e-9, 1e-5, 100000, expected);\n  doTest(new Ackley(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 2*LAMBDA, false, 0, 1e-13,\n  1e-9, 1e-5, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testAckley line 318, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testCigTab",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new CigTab(), startPoint, insigma, boundaries,",
        "test_source": "  public void testCigTab() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.3);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new CigTab(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 5e-5, 100000, expected);\n  doTest(new CigTab(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 5e-5, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testCigTab line 243, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testDiffPow",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new DiffPow(), startPoint, insigma, boundaries,",
        "test_source": "  public void testDiffPow() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new DiffPow(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 10, true, 0, 1e-13,\n  1e-8, 1e-1, 100000, expected);\n  doTest(new DiffPow(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, 10, false, 0, 1e-13,\n  1e-8, 2e-1, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testDiffPow line 288, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testSphere",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Sphere(), startPoint, insigma, boundaries,",
        "test_source": "  public void testSphere() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Sphere(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  doTest(new Sphere(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testSphere line 258, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testTablet",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Tablet(), startPoint, insigma, boundaries,",
        "test_source": "  public void testTablet() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = null;\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Tablet(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  doTest(new Tablet(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testTablet line 273, RetryRunner$1.evaluate line 60"
        ]
      },
      {
        "methodName": "testCigarWithBoundaries",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(new Cigar(), startPoint, insigma, boundaries,",
        "test_source": "  public void testCigarWithBoundaries() {\n  double[] startPoint = point(DIM,1.0);\n  double[] insigma = point(DIM,0.1);\n  double[][] boundaries = boundaries(DIM, -1e100, Double.POSITIVE_INFINITY);\n  PointValuePair expected =\n  new PointValuePair(point(DIM,0.0),0.0);\n  doTest(new Cigar(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n  1e-13, 1e-6, 200000, expected);\n  doTest(new Cigar(), startPoint, insigma, boundaries,\n  GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n  1e-13, 1e-6, 100000, expected);\n  }",
        "stack": [
          "CMAESOptimizerTest.doTest line 514, CMAESOptimizerTest.testCigarWithBoundaries line 213, RetryRunner$1.evaluate line 60"
        ]
      }
    ],
    "org.apache.commons.math3.optim.nonlinear.scalar.noderiv.PowellOptimizerTest": [
      {
        "methodName": "testSumSinc",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-9, 1e-7);",
        "test_source": "  public void testSumSinc() {\n  final MultivariateFunction func = new SumSincFunction(-1);\n\n  int dim = 2;\n  final double[] minPoint = new double[dim];\n  for (int i = 0; i < dim; i++) {\n  minPoint[i] = 0;\n  }\n\n  double[] init = new double[dim];\n\n  // Initial is minimum.\n  for (int i = 0; i < dim; i++) {\n  init[i] = minPoint[i];\n  }\n  doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-9);\n\n  // Initial is far from minimum.\n  for (int i = 0; i < dim; i++) {\n  init[i] = minPoint[i] + 3;\n  }\n  doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-5);\n  // More stringent line search tolerance enhances the precision\n  // of the result.\n  doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-9, 1e-7);\n  }",
        "stack": [
          "PowellOptimizerTest.doTest line 266, PowellOptimizerTest.testSumSinc line 75"
        ]
      }
    ],
    "org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizerMultiDirectionalTest": [
      {
        "methodName": "testMaximize1",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMaximize1() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-11, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(200),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MAXIMIZE,\n  new InitialGuess(new double[] { -3.0, 0.0 }),\n  new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 7e-7);\n  Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 3e-7);\n  Assert.assertEquals(fourExtrema.valueXmYm, optimum.getValue(), 2e-14);\n  Assert.assertTrue(optimizer.getEvaluations() > 120);\n  Assert.assertTrue(optimizer.getEvaluations() < 150);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerMultiDirectionalTest.testMaximize1 line 108"
        ]
      },
      {
        "methodName": "testMaximize2",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMaximize2() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(new SimpleValueChecker(1e-15, 1e-30));\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(200),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MAXIMIZE,\n  new InitialGuess(new double[] { 1, 0 }),\n  new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 2e-8);\n  Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 3e-6);\n  Assert.assertEquals(fourExtrema.valueXpYp, optimum.getValue(), 2e-12);\n  Assert.assertTrue(optimizer.getEvaluations() > 180);\n  Assert.assertTrue(optimizer.getEvaluations() < 220);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerMultiDirectionalTest.testMaximize2 line 129"
        ]
      },
      {
        "methodName": "testMinimize1",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMinimize1() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-11, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(200),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MINIMIZE,\n  new InitialGuess(new double[] { -3, 0 }),\n  new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 4e-6);\n  Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 3e-6);\n  Assert.assertEquals(fourExtrema.valueXmYp, optimum.getValue(), 8e-13);\n  Assert.assertTrue(optimizer.getEvaluations() > 120);\n  Assert.assertTrue(optimizer.getEvaluations() < 150);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerMultiDirectionalTest.testMinimize1 line 66"
        ]
      },
      {
        "methodName": "testMinimize2",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMinimize2() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-11, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(200),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MINIMIZE,\n  new InitialGuess(new double[] { 1, 0 }),\n  new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 2e-8);\n  Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 3e-6);\n  Assert.assertEquals(fourExtrema.valueXpYm, optimum.getValue(), 2e-12);\n  Assert.assertTrue(optimizer.getEvaluations() > 120);\n  Assert.assertTrue(optimizer.getEvaluations() < 150);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerMultiDirectionalTest.testMinimize2 line 87"
        ]
      }
    ],
    "org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizerNelderMeadTest": [
      {
        "methodName": "testMaximize1",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMaximize1() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(100),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MAXIMIZE,\n  new InitialGuess(new double[] { -3, 0 }),\n  new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 1e-5);\n  Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 3e-6);\n  Assert.assertEquals(fourExtrema.valueXmYm, optimum.getValue(), 3e-12);\n  Assert.assertTrue(optimizer.getEvaluations() > 60);\n  Assert.assertTrue(optimizer.getEvaluations() < 90);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerNelderMeadTest.testMaximize1 line 113"
        ]
      },
      {
        "methodName": "testMaximize2",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMaximize2() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(100),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MAXIMIZE,\n  new InitialGuess(new double[] { 1, 0 }),\n  new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 4e-6);\n  Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 5e-6);\n  Assert.assertEquals(fourExtrema.valueXpYp, optimum.getValue(), 7e-12);\n  Assert.assertTrue(optimizer.getEvaluations() > 60);\n  Assert.assertTrue(optimizer.getEvaluations() < 90);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerNelderMeadTest.testMaximize2 line 134"
        ]
      },
      {
        "methodName": "testMinimize1",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMinimize1() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(100),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MINIMIZE,\n  new InitialGuess(new double[] { -3, 0 }),\n  new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 2e-7);\n  Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 2e-5);\n  Assert.assertEquals(fourExtrema.valueXmYp, optimum.getValue(), 6e-12);\n  Assert.assertTrue(optimizer.getEvaluations() > 60);\n  Assert.assertTrue(optimizer.getEvaluations() < 90);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerNelderMeadTest.testMinimize1 line 71"
        ]
      },
      {
        "methodName": "testMinimize2",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "        Assert.assertTrue(optimizer.getIterations() > 0);",
        "test_source": "  public void testMinimize2() {\n  SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n  final FourExtrema fourExtrema = new FourExtrema();\n\n  final PointValuePair optimum\n  = optimizer.optimize(new MaxEval(100),\n  new ObjectiveFunction(fourExtrema),\n  GoalType.MINIMIZE,\n  new InitialGuess(new double[] { 1, 0 }),\n  new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n  Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 5e-6);\n  Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 6e-6);\n  Assert.assertEquals(fourExtrema.valueXpYm, optimum.getValue(), 1e-11);\n  Assert.assertTrue(optimizer.getEvaluations() > 60);\n  Assert.assertTrue(optimizer.getEvaluations() < 90);\n\n  // Check that the number of iterations is updated (MATH-949).\n  Assert.assertTrue(optimizer.getIterations() > 0);\n  }",
        "stack": [
          "SimplexOptimizerNelderMeadTest.testMinimize2 line 92"
        ]
      }
    ],
    "org.apache.commons.math3.optim.nonlinear.vector.jacobian.GaussNewtonOptimizerTest": [
      {
        "methodName": "testGetIterations",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "",
        "test_source": "",
        "stack": [
          "AbstractLeastSquaresOptimizerAbstractTest.testGetIterations line 131"
        ]
      }
    ],
    "org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizerTest": [
      {
        "methodName": "testGetIterations",
        "error": "junit.framework.AssertionFailedError",
        "message": "",
        "fail_line": "",
        "test_source": "",
        "stack": [
          "AbstractLeastSquaresOptimizerAbstractTest.testGetIterations line 131"
        ]
      }
    ]
  },
  "classes": [
    {
      "name": "org/apache/commons/math3/optim/BaseOptimizer.java",
      "buggy_full_code": "\npackage org.apache.commons.math3.optim;\n\nimport org.apache.commons.math3.util.Incrementor;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.TooManyIterationsException;\n\n\npublic abstract class BaseOptimizer<PAIR> { protected final Incrementor evaluations; protected final Incrementor iterations; private ConvergenceChecker<PAIR> checker; protected BaseOptimizer(ConvergenceChecker<PAIR> checker) {\n        this.checker = checker;\n\n        evaluations = new Incrementor(0, new MaxEvalCallback());\n        iterations = new Incrementor(0, new MaxIterCallback());\n    }\n\n    \n    public int getMaxEvaluations() {\n        return evaluations.getMaximalCount();\n    }\n\n    \n    public int getEvaluations() {\n        return evaluations.getCount();\n    }\n\n    \n    public int getMaxIterations() {\n        return iterations.getMaximalCount();\n    }\n\n    \n    public int getIterations() {\n        return iterations.getCount();\n    }\n\n    \n    public ConvergenceChecker<PAIR> getConvergenceChecker() {\n        return checker;\n    }\n\n    \n    public PAIR optimize(OptimizationData... optData) throws TooManyEvaluationsException, TooManyIterationsException {\n        \n        parseOptimizationData(optData);\n\n        \n        evaluations.resetCount();\n        iterations.resetCount();\n        \n        return doOptimize();\n    }\n\n    \n    protected abstract PAIR doOptimize(); protected void incrementEvaluationCount() throws TooManyEvaluationsException {\n        evaluations.incrementCount();\n    }\n\n    \n    protected void incrementIterationCount() throws TooManyIterationsException {\n        iterations.incrementCount();\n    }\n\n    \n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        \n        for (OptimizationData data : optData) {\n            if (data instanceof MaxEval) {\n                evaluations.setMaximalCount(((MaxEval) data).getMaxEval());\n                continue;\n            }\n            if (data instanceof MaxIter) {\n                iterations.setMaximalCount(((MaxIter) data).getMaxIter());\n                continue;\n            }\n        }\n    }\n\n    \n    private static class MaxEvalCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max) {\n            throw new TooManyEvaluationsException(max);\n        }\n    }\n\n    \n    private static class MaxIterCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max) {\n            throw new TooManyIterationsException(max);\n        }\n    }\n}\n",
      "fixed_full_code": "\npackage org.apache.commons.math3.optim;\n\nimport org.apache.commons.math3.util.Incrementor;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.TooManyIterationsException;\n\n\npublic abstract class BaseOptimizer<PAIR> { protected final Incrementor evaluations; protected final Incrementor iterations; private ConvergenceChecker<PAIR> checker; protected BaseOptimizer(ConvergenceChecker<PAIR> checker) {\n        this.checker = checker;\n\n        evaluations = new Incrementor(0, new MaxEvalCallback());\n        iterations = new Incrementor(Integer.MAX_VALUE, new MaxIterCallback());\n    }\n\n    \n    public int getMaxEvaluations() {\n        return evaluations.getMaximalCount();\n    }\n\n    \n    public int getEvaluations() {\n        return evaluations.getCount();\n    }\n\n    \n    public int getMaxIterations() {\n        return iterations.getMaximalCount();\n    }\n\n    \n    public int getIterations() {\n        return iterations.getCount();\n    }\n\n    \n    public ConvergenceChecker<PAIR> getConvergenceChecker() {\n        return checker;\n    }\n\n    \n    public PAIR optimize(OptimizationData... optData) throws TooManyEvaluationsException, TooManyIterationsException {\n        \n        parseOptimizationData(optData);\n\n        \n        evaluations.resetCount();\n        iterations.resetCount();\n        \n        return doOptimize();\n    }\n\n    \n    protected abstract PAIR doOptimize(); protected void incrementEvaluationCount() throws TooManyEvaluationsException {\n        evaluations.incrementCount();\n    }\n\n    \n    protected void incrementIterationCount() throws TooManyIterationsException {\n        iterations.incrementCount();\n    }\n\n    \n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        \n        for (OptimizationData data : optData) {\n            if (data instanceof MaxEval) {\n                evaluations.setMaximalCount(((MaxEval) data).getMaxEval());\n                continue;\n            }\n            if (data instanceof MaxIter) {\n                iterations.setMaximalCount(((MaxIter) data).getMaxIter());\n                continue;\n            }\n        }\n    }\n\n    \n    private static class MaxEvalCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max) {\n            throw new TooManyEvaluationsException(max);\n        }\n    }\n\n    \n    private static class MaxIterCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max) {\n            throw new TooManyIterationsException(max);\n        }\n    }\n}\n",
      "buggy_signatures": [
        "public abstract class BaseOptimizer<PAIR> { protected final Incrementor evaluations; protected final Incrementor iterations; private ConvergenceChecker<PAIR> checker; protected BaseOptimizer(ConvergenceChecker<PAIR> checker)",
        "public int getMaxEvaluations()",
        "public int getEvaluations()",
        "public int getMaxIterations()",
        "public int getIterations()",
        "public ConvergenceChecker<PAIR> getConvergenceChecker()",
        "public PAIR optimize(OptimizationData... optData) throws TooManyEvaluationsException, TooManyIterationsException",
        "protected abstract PAIR doOptimize(); protected void incrementEvaluationCount() throws TooManyEvaluationsException",
        "protected void incrementIterationCount() throws TooManyIterationsException",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private static class MaxEvalCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max)",
        "private static class MaxIterCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max)"
      ],
      "fixed_signatures": [
        "public abstract class BaseOptimizer<PAIR> { protected final Incrementor evaluations; protected final Incrementor iterations; private ConvergenceChecker<PAIR> checker; protected BaseOptimizer(ConvergenceChecker<PAIR> checker)",
        "public int getMaxEvaluations()",
        "public int getEvaluations()",
        "public int getMaxIterations()",
        "public int getIterations()",
        "public ConvergenceChecker<PAIR> getConvergenceChecker()",
        "public PAIR optimize(OptimizationData... optData) throws TooManyEvaluationsException, TooManyIterationsException",
        "protected abstract PAIR doOptimize(); protected void incrementEvaluationCount() throws TooManyEvaluationsException",
        "protected void incrementIterationCount() throws TooManyIterationsException",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private static class MaxEvalCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max)",
        "private static class MaxIterCallback implements Incrementor.MaxCountExceededCallback { public void trigger(int max)"
      ],
      "methods": [
        {
          "buggy_method": "  protected BaseOptimizer(ConvergenceChecker<PAIR> checker) {\n  this.checker = checker;\n\n  evaluations = new Incrementor(0, new MaxEvalCallback());\n  iterations = new Incrementor(0, new MaxIterCallback());\n  }",
          "fixed_method": "  protected BaseOptimizer(ConvergenceChecker<PAIR> checker) {\n  this.checker = checker;\n\n  evaluations = new Incrementor(0, new MaxEvalCallback());\n  iterations = new Incrementor(Integer.MAX_VALUE, new MaxIterCallback());\n  }",
          "diff": [
            "@@ -48,7 +48,7 @@",
            "         this.checker = checker;\n",
            " \n",
            "         evaluations = new Incrementor(0, new MaxEvalCallback());\n",
            "-        iterations = new Incrementor(0, new MaxIterCallback());\n",
            "+        iterations = new Incrementor(Integer.MAX_VALUE, new MaxIterCallback());\n",
            "     }\n",
            " \n",
            "     /**\n"
          ],
          "changed_lines": 2
        }
      ]
    },
    {
      "name": "org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java",
      "buggy_full_code": "\n\npackage org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n\nimport org.apache.commons.math3.analysis.UnivariateFunction;\nimport org.apache.commons.math3.analysis.solvers.BrentSolver;\nimport org.apache.commons.math3.analysis.solvers.UnivariateSolver;\nimport org.apache.commons.math3.exception.MathInternalError;\nimport org.apache.commons.math3.exception.MathIllegalStateException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GradientMultivariateOptimizer;\nimport org.apache.commons.math3.util.FastMath;\n\n\npublic class NonLinearConjugateGradientOptimizer extends GradientMultivariateOptimizer { private final Formula updateFormula; private final Preconditioner preconditioner; private final UnivariateSolver solver; private double initialStep = 1; public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker) {\n        this(updateFormula,\n             checker,\n             new BrentSolver(),\n             new IdentityPreconditioner());\n    }\n\n    \n    public static enum Formula { FLETCHER_REEVES, POLAK_RIBIERE } public static class BracketingStep implements OptimizationData { private final double initialStep; public BracketingStep(double step) {\n            initialStep = step;\n        }\n\n        \n        public double getBracketingStep() {\n            return initialStep;\n        }\n    }\n\n    \n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver) {\n        this(updateFormula,\n             checker,\n             lineSearchSolver,\n             new IdentityPreconditioner());\n    }\n\n    \n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver, final Preconditioner preconditioner) {\n        super(checker);\n\n        this.updateFormula = updateFormula;\n        solver = lineSearchSolver;\n        this.preconditioner = preconditioner;\n        initialStep = 1;\n    }\n\n    \n    @Override\n    public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException {\n        \n        return super.optimize(optData);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n        final double[] point = getStartPoint();\n        final GoalType goal = getGoalType();\n        final int n = point.length;\n        double[] r = computeObjectiveGradient(point);\n        if (goal == GoalType.MINIMIZE) {\n            for (int i = 0; i < n; i++) {\n                r[i] = -r[i];\n            }\n        }\n\n        \n        double[] steepestDescent = preconditioner.precondition(point, r);\n        double[] searchDirection = steepestDescent.clone();\n\n        double delta = 0;\n        for (int i = 0; i < n; ++i) {\n            delta += r[i] * searchDirection[i];\n        }\n\n        PointValuePair current = null;\n        int iter = 0;\n        int maxEval = getMaxEvaluations();\n        while (true) {\n            ++iter;\n\n            final double objective = computeObjectiveValue(point);\n            PointValuePair previous = current;\n            current = new PointValuePair(point, objective);\n            if (previous != null) {\n                if (checker.converged(iter, previous, current)) {\n                    \n                    return current;\n                }\n            }\n\n            \n            final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n            final double uB = findUpperBound(lsf, 0, initialStep);\n            \n            \n            \n            final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n            maxEval -= solver.getEvaluations(); \n\n            \n            for (int i = 0; i < point.length; ++i) {\n                point[i] += step * searchDirection[i];\n            }\n\n            r = computeObjectiveGradient(point);\n            if (goal == GoalType.MINIMIZE) {\n                for (int i = 0; i < n; ++i) {\n                    r[i] = -r[i];\n                }\n            }\n\n            \n            final double deltaOld = delta;\n            final double[] newSteepestDescent = preconditioner.precondition(point, r);\n            delta = 0;\n            for (int i = 0; i < n; ++i) {\n                delta += r[i] * newSteepestDescent[i];\n            }\n\n            final double beta;\n            switch (updateFormula) {\n            case FLETCHER_REEVES:\n                beta = delta / deltaOld;\n                break;\n            case POLAK_RIBIERE:\n                double deltaMid = 0;\n                for (int i = 0; i < r.length; ++i) {\n                    deltaMid += r[i] * steepestDescent[i];\n                }\n                beta = (delta - deltaMid) / deltaOld;\n                break;\n            default:\n                \n                throw new MathInternalError();\n            }\n            steepestDescent = newSteepestDescent;\n\n            \n            if (iter % n == 0 ||\n                beta < 0) {\n                \n                searchDirection = steepestDescent.clone();\n            } else {\n                \n                for (int i = 0; i < n; ++i) {\n                    searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n                }\n            }\n        }\n    }\n\n    \n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        super.parseOptimizationData(optData);\n\n        \n        \n        for (OptimizationData data : optData) {\n            if  (data instanceof BracketingStep) {\n                initialStep = ((BracketingStep) data).getBracketingStep();\n                \n                \n                break;\n            }\n        }\n\n        checkParameters();\n    }\n\n    \n    private double findUpperBound(final UnivariateFunction f, final double a, final double h) {\n        final double yA = f.value(a);\n        double yB = yA;\n        for (double step = h; step < Double.MAX_VALUE; step *= FastMath.max(2, yA / yB)) {\n            final double b = a + step;\n            yB = f.value(b);\n            if (yA * yB <= 0) {\n                return b;\n            }\n        }\n        throw new MathIllegalStateException(LocalizedFormats.UNABLE_TO_BRACKET_OPTIMUM_IN_LINE_SEARCH);\n    }\n\n    \n    public static class IdentityPreconditioner implements Preconditioner { public double[] precondition(double[] variables, double[] r) {\n            return r.clone();\n        }\n    }\n\n    \n    private class LineSearchFunction implements UnivariateFunction { private final double[] currentPoint; private final double[] searchDirection; public LineSearchFunction(double[] point, double[] direction) {\n            currentPoint = point.clone();\n            searchDirection = direction.clone();\n        }\n\n        \n        public double value(double x) {\n            \n            final double[] shiftedPoint = currentPoint.clone();\n            for (int i = 0; i < shiftedPoint.length; ++i) {\n                shiftedPoint[i] += x * searchDirection[i];\n            }\n\n            \n            final double[] gradient = computeObjectiveGradient(shiftedPoint);\n\n            \n            double dotProduct = 0;\n            for (int i = 0; i < gradient.length; ++i) {\n                dotProduct += gradient[i] * searchDirection[i];\n            }\n\n            return dotProduct;\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "fixed_full_code": "\n\npackage org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n\nimport org.apache.commons.math3.analysis.UnivariateFunction;\nimport org.apache.commons.math3.analysis.solvers.BrentSolver;\nimport org.apache.commons.math3.analysis.solvers.UnivariateSolver;\nimport org.apache.commons.math3.exception.MathInternalError;\nimport org.apache.commons.math3.exception.MathIllegalStateException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GradientMultivariateOptimizer;\nimport org.apache.commons.math3.util.FastMath;\n\n\npublic class NonLinearConjugateGradientOptimizer extends GradientMultivariateOptimizer { private final Formula updateFormula; private final Preconditioner preconditioner; private final UnivariateSolver solver; private double initialStep = 1; public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker) {\n        this(updateFormula,\n             checker,\n             new BrentSolver(),\n             new IdentityPreconditioner());\n    }\n\n    \n    public static enum Formula { FLETCHER_REEVES, POLAK_RIBIERE } public static class BracketingStep implements OptimizationData { private final double initialStep; public BracketingStep(double step) {\n            initialStep = step;\n        }\n\n        \n        public double getBracketingStep() {\n            return initialStep;\n        }\n    }\n\n    \n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver) {\n        this(updateFormula,\n             checker,\n             lineSearchSolver,\n             new IdentityPreconditioner());\n    }\n\n    \n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver, final Preconditioner preconditioner) {\n        super(checker);\n\n        this.updateFormula = updateFormula;\n        solver = lineSearchSolver;\n        this.preconditioner = preconditioner;\n        initialStep = 1;\n    }\n\n    \n    @Override\n    public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException {\n        \n        return super.optimize(optData);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n        final double[] point = getStartPoint();\n        final GoalType goal = getGoalType();\n        final int n = point.length;\n        double[] r = computeObjectiveGradient(point);\n        if (goal == GoalType.MINIMIZE) {\n            for (int i = 0; i < n; i++) {\n                r[i] = -r[i];\n            }\n        }\n\n        \n        double[] steepestDescent = preconditioner.precondition(point, r);\n        double[] searchDirection = steepestDescent.clone();\n\n        double delta = 0;\n        for (int i = 0; i < n; ++i) {\n            delta += r[i] * searchDirection[i];\n        }\n\n        PointValuePair current = null;\n        int maxEval = getMaxEvaluations();\n        while (true) {\n            incrementIterationCount();\n\n            final double objective = computeObjectiveValue(point);\n            PointValuePair previous = current;\n            current = new PointValuePair(point, objective);\n            if (previous != null) {\n                if (checker.converged(getIterations(), previous, current)) {\n                    \n                    return current;\n                }\n            }\n\n            \n            final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n            final double uB = findUpperBound(lsf, 0, initialStep);\n            \n            \n            \n            final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n            maxEval -= solver.getEvaluations(); \n\n            \n            for (int i = 0; i < point.length; ++i) {\n                point[i] += step * searchDirection[i];\n            }\n\n            r = computeObjectiveGradient(point);\n            if (goal == GoalType.MINIMIZE) {\n                for (int i = 0; i < n; ++i) {\n                    r[i] = -r[i];\n                }\n            }\n\n            \n            final double deltaOld = delta;\n            final double[] newSteepestDescent = preconditioner.precondition(point, r);\n            delta = 0;\n            for (int i = 0; i < n; ++i) {\n                delta += r[i] * newSteepestDescent[i];\n            }\n\n            final double beta;\n            switch (updateFormula) {\n            case FLETCHER_REEVES:\n                beta = delta / deltaOld;\n                break;\n            case POLAK_RIBIERE:\n                double deltaMid = 0;\n                for (int i = 0; i < r.length; ++i) {\n                    deltaMid += r[i] * steepestDescent[i];\n                }\n                beta = (delta - deltaMid) / deltaOld;\n                break;\n            default:\n                \n                throw new MathInternalError();\n            }\n            steepestDescent = newSteepestDescent;\n\n            \n            if (getIterations() % n == 0 ||\n                beta < 0) {\n                \n                searchDirection = steepestDescent.clone();\n            } else {\n                \n                for (int i = 0; i < n; ++i) {\n                    searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n                }\n            }\n        }\n    }\n\n    \n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        super.parseOptimizationData(optData);\n\n        \n        \n        for (OptimizationData data : optData) {\n            if  (data instanceof BracketingStep) {\n                initialStep = ((BracketingStep) data).getBracketingStep();\n                \n                \n                break;\n            }\n        }\n\n        checkParameters();\n    }\n\n    \n    private double findUpperBound(final UnivariateFunction f, final double a, final double h) {\n        final double yA = f.value(a);\n        double yB = yA;\n        for (double step = h; step < Double.MAX_VALUE; step *= FastMath.max(2, yA / yB)) {\n            final double b = a + step;\n            yB = f.value(b);\n            if (yA * yB <= 0) {\n                return b;\n            }\n        }\n        throw new MathIllegalStateException(LocalizedFormats.UNABLE_TO_BRACKET_OPTIMUM_IN_LINE_SEARCH);\n    }\n\n    \n    public static class IdentityPreconditioner implements Preconditioner { public double[] precondition(double[] variables, double[] r) {\n            return r.clone();\n        }\n    }\n\n    \n    private class LineSearchFunction implements UnivariateFunction { private final double[] currentPoint; private final double[] searchDirection; public LineSearchFunction(double[] point, double[] direction) {\n            currentPoint = point.clone();\n            searchDirection = direction.clone();\n        }\n\n        \n        public double value(double x) {\n            \n            final double[] shiftedPoint = currentPoint.clone();\n            for (int i = 0; i < shiftedPoint.length; ++i) {\n                shiftedPoint[i] += x * searchDirection[i];\n            }\n\n            \n            final double[] gradient = computeObjectiveGradient(shiftedPoint);\n\n            \n            double dotProduct = 0;\n            for (int i = 0; i < gradient.length; ++i) {\n                dotProduct += gradient[i] * searchDirection[i];\n            }\n\n            return dotProduct;\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "buggy_signatures": [
        "public static enum Formula { FLETCHER_REEVES, POLAK_RIBIERE } public static class BracketingStep implements OptimizationData { private final double initialStep; public BracketingStep(double step)",
        "public double getBracketingStep()",
        "public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver)",
        "public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver, final Preconditioner preconditioner)",
        "public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException",
        "protected PointValuePair doOptimize()",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private double findUpperBound(final UnivariateFunction f, final double a, final double h)",
        "public static class IdentityPreconditioner implements Preconditioner { public double[] precondition(double[] variables, double[] r)",
        "private class LineSearchFunction implements UnivariateFunction { private final double[] currentPoint; private final double[] searchDirection; public LineSearchFunction(double[] point, double[] direction)",
        "public double value(double x)",
        "private void checkParameters()"
      ],
      "fixed_signatures": [
        "public static enum Formula { FLETCHER_REEVES, POLAK_RIBIERE } public static class BracketingStep implements OptimizationData { private final double initialStep; public BracketingStep(double step)",
        "public double getBracketingStep()",
        "public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver)",
        "public NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver, final Preconditioner preconditioner)",
        "public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException",
        "protected PointValuePair doOptimize()",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private double findUpperBound(final UnivariateFunction f, final double a, final double h)",
        "public static class IdentityPreconditioner implements Preconditioner { public double[] precondition(double[] variables, double[] r)",
        "private class LineSearchFunction implements UnivariateFunction { private final double[] currentPoint; private final double[] searchDirection; public LineSearchFunction(double[] point, double[] direction)",
        "public double value(double x)",
        "private void checkParameters()"
      ],
      "methods": [
        {
          "buggy_method": "  protected PointValuePair doOptimize() {\n  final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n  final double[] point = getStartPoint();\n  final GoalType goal = getGoalType();\n  final int n = point.length;\n  double[] r = computeObjectiveGradient(point);\n  if (goal == GoalType.MINIMIZE) {\n  for (int i = 0; i < n; i++) {\n  r[i] = -r[i];\n  }\n  }\n\n  \n  double[] steepestDescent = preconditioner.precondition(point, r);\n  double[] searchDirection = steepestDescent.clone();\n\n  double delta = 0;\n  for (int i = 0; i < n; ++i) {\n  delta += r[i] * searchDirection[i];\n  }\n\n  PointValuePair current = null;\n  int iter = 0;\n  int maxEval = getMaxEvaluations();\n  while (true) {\n  ++iter;\n\n  final double objective = computeObjectiveValue(point);\n  PointValuePair previous = current;\n  current = new PointValuePair(point, objective);\n  if (previous != null) {\n  if (checker.converged(iter, previous, current)) {\n  \n  return current;\n  }\n  }\n\n  \n  final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n  final double uB = findUpperBound(lsf, 0, initialStep);\n  \n  \n  \n  final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n  maxEval -= solver.getEvaluations(); \n\n  \n  for (int i = 0; i < point.length; ++i) {\n  point[i] += step * searchDirection[i];\n  }\n\n  r = computeObjectiveGradient(point);\n  if (goal == GoalType.MINIMIZE) {\n  for (int i = 0; i < n; ++i) {\n  r[i] = -r[i];\n  }\n  }\n\n  \n  final double deltaOld = delta;\n  final double[] newSteepestDescent = preconditioner.precondition(point, r);\n  delta = 0;\n  for (int i = 0; i < n; ++i) {\n  delta += r[i] * newSteepestDescent[i];\n  }\n\n  final double beta;\n  switch (updateFormula) {\n  case FLETCHER_REEVES:\n  beta = delta / deltaOld;\n  break;\n  case POLAK_RIBIERE:\n  double deltaMid = 0;\n  for (int i = 0; i < r.length; ++i) {\n  deltaMid += r[i] * steepestDescent[i];\n  }\n  beta = (delta - deltaMid) / deltaOld;\n  break;\n  default:\n  \n  throw new MathInternalError();\n  }\n  steepestDescent = newSteepestDescent;\n\n  \n  if (iter % n == 0 ||\n  beta < 0) {\n  \n  searchDirection = steepestDescent.clone();\n  } else {\n  \n  for (int i = 0; i < n; ++i) {\n  searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n  }\n  }\n  }\n  }",
          "fixed_method": "  protected PointValuePair doOptimize() {\n  final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n  final double[] point = getStartPoint();\n  final GoalType goal = getGoalType();\n  final int n = point.length;\n  double[] r = computeObjectiveGradient(point);\n  if (goal == GoalType.MINIMIZE) {\n  for (int i = 0; i < n; i++) {\n  r[i] = -r[i];\n  }\n  }\n\n  \n  double[] steepestDescent = preconditioner.precondition(point, r);\n  double[] searchDirection = steepestDescent.clone();\n\n  double delta = 0;\n  for (int i = 0; i < n; ++i) {\n  delta += r[i] * searchDirection[i];\n  }\n\n  PointValuePair current = null;\n  int maxEval = getMaxEvaluations();\n  while (true) {\n  incrementIterationCount();\n\n  final double objective = computeObjectiveValue(point);\n  PointValuePair previous = current;\n  current = new PointValuePair(point, objective);\n  if (previous != null) {\n  if (checker.converged(getIterations(), previous, current)) {\n  \n  return current;\n  }\n  }\n\n  \n  final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n  final double uB = findUpperBound(lsf, 0, initialStep);\n  \n  \n  \n  final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n  maxEval -= solver.getEvaluations(); \n\n  \n  for (int i = 0; i < point.length; ++i) {\n  point[i] += step * searchDirection[i];\n  }\n\n  r = computeObjectiveGradient(point);\n  if (goal == GoalType.MINIMIZE) {\n  for (int i = 0; i < n; ++i) {\n  r[i] = -r[i];\n  }\n  }\n\n  \n  final double deltaOld = delta;\n  final double[] newSteepestDescent = preconditioner.precondition(point, r);\n  delta = 0;\n  for (int i = 0; i < n; ++i) {\n  delta += r[i] * newSteepestDescent[i];\n  }\n\n  final double beta;\n  switch (updateFormula) {\n  case FLETCHER_REEVES:\n  beta = delta / deltaOld;\n  break;\n  case POLAK_RIBIERE:\n  double deltaMid = 0;\n  for (int i = 0; i < r.length; ++i) {\n  deltaMid += r[i] * steepestDescent[i];\n  }\n  beta = (delta - deltaMid) / deltaOld;\n  break;\n  default:\n  \n  throw new MathInternalError();\n  }\n  steepestDescent = newSteepestDescent;\n\n  \n  if (getIterations() % n == 0 ||\n  beta < 0) {\n  \n  searchDirection = steepestDescent.clone();\n  } else {\n  \n  for (int i = 0; i < n; ++i) {\n  searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n  }\n  }\n  }\n  }",
          "diff": [
            "@@ -211,16 +211,15 @@",
            "         }\n",
            " \n",
            "         PointValuePair current = null;\n",
            "-        int iter = 0;\n",
            "         int maxEval = getMaxEvaluations();\n",
            "         while (true) {\n",
            "-            ++iter;\n",
            "+            incrementIterationCount();\n",
            " \n",
            "             final double objective = computeObjectiveValue(point);\n",
            "             PointValuePair previous = current;\n",
            "             current = new PointValuePair(point, objective);\n",
            "             if (previous != null) {\n",
            "-                if (checker.converged(iter, previous, current)) {\n",
            "+                if (checker.converged(getIterations(), previous, current)) {\n",
            "                     // We have found an optimum.\n",
            "                     return current;\n",
            "                 }\n",
            "@@ -274,7 +273,7 @@",
            "             steepestDescent = newSteepestDescent;\n",
            " \n",
            "             // Compute conjugate search direction.\n",
            "-            if (iter % n == 0 ||\n",
            "+            if (getIterations() % n == 0 ||\n",
            "                 beta < 0) {\n",
            "                 // Break conjugation: reset search direction.\n",
            "                 searchDirection = steepestDescent.clone();\n"
          ],
          "changed_lines": 7
        }
      ]
    },
    {
      "name": "org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java",
      "buggy_full_code": "\n\npackage org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport org.apache.commons.math3.exception.DimensionMismatchException;\nimport org.apache.commons.math3.exception.NotPositiveException;\nimport org.apache.commons.math3.exception.NotStrictlyPositiveException;\nimport org.apache.commons.math3.exception.OutOfRangeException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.linear.Array2DRowRealMatrix;\nimport org.apache.commons.math3.linear.EigenDecomposition;\nimport org.apache.commons.math3.linear.MatrixUtils;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\nimport org.apache.commons.math3.random.RandomGenerator;\nimport org.apache.commons.math3.util.MathArrays;\n\n\npublic class CMAESOptimizer extends MultivariateOptimizer { private int lambda; private final boolean isActiveCMA; private final int checkFeasableCount; private double[] inputSigma; private int dimension; private int diagonalOnly; private boolean isMinimize = true; private final boolean generateStatistics; private final int maxIterations; private final double stopFitness; private double stopTolUpX; private double stopTolX; private double stopTolFun; private double stopTolHistFun; private int mu; private double logMu2; private RealMatrix weights; private double mueff; private double sigma; private double cc; private double cs; private double damps; private double ccov1; private double ccovmu; private double chiN; private double ccov1Sep; private double ccovmuSep; private RealMatrix xmean; private RealMatrix pc; private RealMatrix ps; private double normps; private RealMatrix B; private RealMatrix D; private RealMatrix BD; private RealMatrix diagD; private RealMatrix C; private RealMatrix diagC; private int iterations; private double[] fitnessHistory; private int historySize; private final RandomGenerator random; private final List<Double> statisticsSigmaHistory = new ArrayList<Double>(); private final List<RealMatrix> statisticsMeanHistory = new ArrayList<RealMatrix>(); private final List<Double> statisticsFitnessHistory = new ArrayList<Double>(); private final List<RealMatrix> statisticsDHistory = new ArrayList<RealMatrix>(); public CMAESOptimizer(int maxIterations, double stopFitness, boolean isActiveCMA, int diagonalOnly, int checkFeasableCount, RandomGenerator random, boolean generateStatistics, ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n        this.maxIterations = maxIterations;\n        this.stopFitness = stopFitness;\n        this.isActiveCMA = isActiveCMA;\n        this.diagonalOnly = diagonalOnly;\n        this.checkFeasableCount = checkFeasableCount;\n        this.random = random;\n        this.generateStatistics = generateStatistics;\n    }\n\n    \n    public List<Double> getStatisticsSigmaHistory() {\n        return statisticsSigmaHistory;\n    }\n\n    \n    public List<RealMatrix> getStatisticsMeanHistory() {\n        return statisticsMeanHistory;\n    }\n\n    \n    public List<Double> getStatisticsFitnessHistory() {\n        return statisticsFitnessHistory;\n    }\n\n    \n    public List<RealMatrix> getStatisticsDHistory() {\n        return statisticsDHistory;\n    }\n\n    \n    public static class Sigma implements OptimizationData { private final double[] sigma; public Sigma(double[] s) throws NotPositiveException {\n            for (int i = 0; i < s.length; i++) {\n                if (s[i] < 0) {\n                    throw new NotPositiveException(s[i]);\n                }\n            }\n\n            sigma = s.clone();\n        }\n\n        \n        public double[] getSigma() {\n            return sigma.clone();\n        }\n    }\n\n    \n    public static class PopulationSize implements OptimizationData { private final int lambda; public PopulationSize(int size) throws NotStrictlyPositiveException {\n            if (size <= 0) {\n                throw new NotStrictlyPositiveException(size);\n            }\n            lambda = size;\n        }\n\n        \n        public int getPopulationSize() {\n            return lambda;\n        }\n    }\n\n    \n    @Override\n    public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException, DimensionMismatchException {\n        \n        return super.optimize(optData);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n         \n        isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n        final FitnessFunction fitfun = new FitnessFunction();\n        final double[] guess = getStartPoint();\n        \n        dimension = guess.length;\n        initializeCMA(guess);\n        iterations = 0;\n        double bestValue = fitfun.value(guess);\n        push(fitnessHistory, bestValue);\n        PointValuePair optimum\n            = new PointValuePair(getStartPoint(),\n                                 isMinimize ? bestValue : -bestValue);\n        PointValuePair lastResult = null;\n\n        \n\n        generationLoop:\n        for (iterations = 1; iterations <= maxIterations; iterations++) {\n\n            \n            final RealMatrix arz = randn1(dimension, lambda);\n            final RealMatrix arx = zeros(dimension, lambda);\n            final double[] fitness = new double[lambda];\n            \n            for (int k = 0; k < lambda; k++) {\n                RealMatrix arxk = null;\n                for (int i = 0; i < checkFeasableCount + 1; i++) {\n                    if (diagonalOnly <= 0) {\n                        arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n                                         .scalarMultiply(sigma)); \n                    } else {\n                        arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n                                         .scalarMultiply(sigma));\n                    }\n                    if (i >= checkFeasableCount ||\n                        fitfun.isFeasible(arxk.getColumn(0))) {\n                        break;\n                    }\n                    \n                    arz.setColumn(k, randn(dimension));\n                }\n                copyColumn(arxk, 0, arx, k);\n                try {\n                    fitness[k] = fitfun.value(arx.getColumn(k)); \n                } catch (TooManyEvaluationsException e) {\n                    break generationLoop;\n                }\n            }\n            \n            final int[] arindex = sortedIndices(fitness);\n            \n            final RealMatrix xold = xmean; \n            final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n            xmean = bestArx.multiply(weights);\n            final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n            final RealMatrix zmean = bestArz.multiply(weights);\n            final boolean hsig = updateEvolutionPaths(zmean, xold);\n            if (diagonalOnly <= 0) {\n                updateCovariance(hsig, bestArx, arz, arindex, xold);\n            } else {\n                updateCovarianceDiagonalOnly(hsig, bestArz);\n            }\n            \n            sigma *= Math.exp(Math.min(1, (normps/chiN - 1) * cs / damps));\n            final double bestFitness = fitness[arindex[0]];\n            final double worstFitness = fitness[arindex[arindex.length - 1]];\n            if (bestValue > bestFitness) {\n                bestValue = bestFitness;\n                lastResult = optimum;\n                optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)),\n                                             isMinimize ? bestFitness : -bestFitness);\n                if (getConvergenceChecker() != null &&\n                    lastResult != null) {\n                    if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n                        break generationLoop;\n                    }\n                }\n            }\n            \n            \n            if (stopFitness != 0) { \n                if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n                    break generationLoop;\n                }\n            }\n            final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n            final double[] pcCol = pc.getColumn(0);\n            for (int i = 0; i < dimension; i++) {\n                if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n                    break;\n                }\n                if (i >= dimension - 1) {\n                    break generationLoop;\n                }\n            }\n            for (int i = 0; i < dimension; i++) {\n                if (sigma * sqrtDiagC[i] > stopTolUpX) {\n                    break generationLoop;\n                }\n            }\n            final double historyBest = min(fitnessHistory);\n            final double historyWorst = max(fitnessHistory);\n            if (iterations > 2 &&\n                Math.max(historyWorst, worstFitness) -\n                Math.min(historyBest, bestFitness) < stopTolFun) {\n                break generationLoop;\n            }\n            if (iterations > fitnessHistory.length &&\n                historyWorst - historyBest < stopTolHistFun) {\n                break generationLoop;\n            }\n            \n            if (max(diagD) / min(diagD) > 1e7) {\n                break generationLoop;\n            }\n            \n            if (getConvergenceChecker() != null) {\n                final PointValuePair current\n                    = new PointValuePair(bestArx.getColumn(0),\n                                         isMinimize ? bestFitness : -bestFitness);\n                if (lastResult != null &&\n                    getConvergenceChecker().converged(iterations, current, lastResult)) {\n                    break generationLoop;\n                    }\n                lastResult = current;\n            }\n            \n            if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n                sigma = sigma * Math.exp(0.2 + cs / damps);\n            }\n            if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n                Math.min(historyBest, bestFitness) == 0) {\n                sigma = sigma * Math.exp(0.2 + cs / damps);\n            }\n            \n            push(fitnessHistory,bestFitness);\n            fitfun.setValueRange(worstFitness-bestFitness);\n            if (generateStatistics) {\n                statisticsSigmaHistory.add(sigma);\n                statisticsFitnessHistory.add(bestFitness);\n                statisticsMeanHistory.add(xmean.transpose());\n                statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n            }\n        }\n        return optimum;\n    }\n\n    \n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        super.parseOptimizationData(optData);\n\n        \n        \n        for (OptimizationData data : optData) {\n            if (data instanceof Sigma) {\n                inputSigma = ((Sigma) data).getSigma();\n                continue;\n            }\n            if (data instanceof PopulationSize) {\n                lambda = ((PopulationSize) data).getPopulationSize();\n                continue;\n            }\n        }\n\n        checkParameters();\n    }\n\n    \n    private void checkParameters() {\n        final double[] init = getStartPoint();\n        final double[] lB = getLowerBound();\n        final double[] uB = getUpperBound();\n\n        if (inputSigma != null) {\n            if (inputSigma.length != init.length) {\n                throw new DimensionMismatchException(inputSigma.length, init.length);\n            }\n            for (int i = 0; i < init.length; i++) {\n                if (inputSigma[i] > uB[i] - lB[i]) {\n                    throw new OutOfRangeException(inputSigma[i], 0, uB[i] - lB[i]);\n                }\n            }\n        }\n    }\n\n    \n    private void initializeCMA(double[] guess) {\n        if (lambda <= 0) {\n            throw new NotStrictlyPositiveException(lambda);\n        }\n        \n        final double[][] sigmaArray = new double[guess.length][1];\n        for (int i = 0; i < guess.length; i++) {\n            sigmaArray[i][0] = inputSigma[i];\n        }\n        final RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);\n        sigma = max(insigma); \n\n        \n        stopTolUpX = 1e3 * max(insigma);\n        stopTolX = 1e-11 * max(insigma);\n        stopTolFun = 1e-12;\n        stopTolHistFun = 1e-13;\n\n        \n        mu = lambda / 2; \n        logMu2 = Math.log(mu + 0.5);\n        weights = log(sequence(1, mu, 1)).scalarMultiply(-1).scalarAdd(logMu2);\n        double sumw = 0;\n        double sumwq = 0;\n        for (int i = 0; i < mu; i++) {\n            double w = weights.getEntry(i, 0);\n            sumw += w;\n            sumwq += w * w;\n        }\n        weights = weights.scalarMultiply(1 / sumw);\n        mueff = sumw * sumw / sumwq; \n\n        \n        cc = (4 + mueff / dimension) /\n                (dimension + 4 + 2 * mueff / dimension);\n        cs = (mueff + 2) / (dimension + mueff + 3.);\n        damps = (1 + 2 * Math.max(0, Math.sqrt((mueff - 1) /\n                                               (dimension + 1)) - 1)) *\n            Math.max(0.3,\n                     1 - dimension / (1e-6 + maxIterations)) + cs; \n        ccov1 = 2 / ((dimension + 1.3) * (dimension + 1.3) + mueff);\n        ccovmu = Math.min(1 - ccov1, 2 * (mueff - 2 + 1 / mueff) /\n                          ((dimension + 2) * (dimension + 2) + mueff));\n        ccov1Sep = Math.min(1, ccov1 * (dimension + 1.5) / 3);\n        ccovmuSep = Math.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3);\n        chiN = Math.sqrt(dimension) *\n            (1 - 1 / ((double) 4 * dimension) + 1 / ((double) 21 * dimension * dimension));\n        \n        xmean = MatrixUtils.createColumnRealMatrix(guess); \n        diagD = insigma.scalarMultiply(1 / sigma);\n        diagC = square(diagD);\n        pc = zeros(dimension, 1); \n        ps = zeros(dimension, 1); \n        normps = ps.getFrobeniusNorm();\n\n        B = eye(dimension, dimension);\n        D = ones(dimension, 1); \n        BD = times(B, repmat(diagD.transpose(), dimension, 1));\n        C = B.multiply(diag(square(D)).multiply(B.transpose())); \n        historySize = 10 + (int) (3 * 10 * dimension / (double) lambda);\n        fitnessHistory = new double[historySize]; \n        for (int i = 0; i < historySize; i++) {\n            fitnessHistory[i] = Double.MAX_VALUE;\n        }\n    }\n\n    \n    private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold) {\n        ps = ps.scalarMultiply(1 - cs).add(\n                B.multiply(zmean).scalarMultiply(\n                        Math.sqrt(cs * (2 - cs) * mueff)));\n        normps = ps.getFrobeniusNorm();\n        final boolean hsig = normps /\n            Math.sqrt(1 - Math.pow(1 - cs, 2 * iterations)) /\n            chiN < 1.4 + 2 / ((double) dimension + 1);\n        pc = pc.scalarMultiply(1 - cc);\n        if (hsig) {\n            pc = pc.add(xmean.subtract(xold).scalarMultiply(Math.sqrt(cc * (2 - cc) * mueff) / sigma));\n        }\n        return hsig;\n    }\n\n    \n    private void updateCovarianceDiagonalOnly(boolean hsig, final RealMatrix bestArz) {\n        \n        double oldFac = hsig ? 0 : ccov1Sep * cc * (2 - cc);\n        oldFac += 1 - ccov1Sep - ccovmuSep;\n        diagC = diagC.scalarMultiply(oldFac) \n            .add(square(pc).scalarMultiply(ccov1Sep)) \n            .add((times(diagC, square(bestArz).multiply(weights))) \n                 .scalarMultiply(ccovmuSep));\n        diagD = sqrt(diagC); \n        if (diagonalOnly > 1 &&\n            iterations > diagonalOnly) {\n            \n            diagonalOnly = 0;\n            B = eye(dimension, dimension);\n            BD = diag(diagD);\n            C = diag(diagC);\n        }\n    }\n\n    \n    private void updateCovariance(boolean hsig, final RealMatrix bestArx, final RealMatrix arz, final int[] arindex, final RealMatrix xold) {\n        double negccov = 0;\n        if (ccov1 + ccovmu > 0) {\n            final RealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))\n                .scalarMultiply(1 / sigma); \n            final RealMatrix roneu = pc.multiply(pc.transpose())\n                .scalarMultiply(ccov1); \n            \n            double oldFac = hsig ? 0 : ccov1 * cc * (2 - cc);\n            oldFac += 1 - ccov1 - ccovmu;\n            if (isActiveCMA) {\n                \n                negccov = (1 - ccovmu) * 0.25 * mueff /\n                    (Math.pow(dimension + 2, 1.5) + 2 * mueff);\n                \n                \n                final double negminresidualvariance = 0.66;\n                \n                final double negalphaold = 0.5;\n                \n                final int[] arReverseIndex = reverse(arindex);\n                RealMatrix arzneg = selectColumns(arz, MathArrays.copyOf(arReverseIndex, mu));\n                RealMatrix arnorms = sqrt(sumRows(square(arzneg)));\n                final int[] idxnorms = sortedIndices(arnorms.getRow(0));\n                final RealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);\n                final int[] idxReverse = reverse(idxnorms);\n                final RealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);\n                arnorms = divide(arnormsReverse, arnormsSorted);\n                final int[] idxInv = inverse(idxnorms);\n                final RealMatrix arnormsInv = selectColumns(arnorms, idxInv);\n                \n                final double negcovMax = (1 - negminresidualvariance) /\n                    square(arnormsInv).multiply(weights).getEntry(0, 0);\n                if (negccov > negcovMax) {\n                    negccov = negcovMax;\n                }\n                arzneg = times(arzneg, repmat(arnormsInv, dimension, 1));\n                final RealMatrix artmp = BD.multiply(arzneg);\n                final RealMatrix Cneg = artmp.multiply(diag(weights)).multiply(artmp.transpose());\n                oldFac += negalphaold * negccov;\n                C = C.scalarMultiply(oldFac)\n                    .add(roneu) \n                    .add(arpos.scalarMultiply( \n                                              ccovmu + (1 - negalphaold) * negccov) \n                         .multiply(times(repmat(weights, 1, dimension),\n                                         arpos.transpose())))\n                    .subtract(Cneg.scalarMultiply(negccov));\n            } else {\n                \n                C = C.scalarMultiply(oldFac) \n                    .add(roneu) \n                    .add(arpos.scalarMultiply(ccovmu) \n                         .multiply(times(repmat(weights, 1, dimension),\n                                         arpos.transpose())));\n            }\n        }\n        updateBD(negccov);\n    }\n\n    \n    private void updateBD(double negccov) {\n        if (ccov1 + ccovmu + negccov > 0 &&\n            (iterations % 1. / (ccov1 + ccovmu + negccov) / dimension / 10.) < 1) {\n            \n            C = triu(C, 0).add(triu(C, 1).transpose());\n            \n            final EigenDecomposition eig = new EigenDecomposition(C);\n            B = eig.getV(); \n            D = eig.getD();\n            diagD = diag(D);\n            if (min(diagD) <= 0) {\n                for (int i = 0; i < dimension; i++) {\n                    if (diagD.getEntry(i, 0) < 0) {\n                        diagD.setEntry(i, 0, 0);\n                    }\n                }\n                final double tfac = max(diagD) / 1e14;\n                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n            }\n            if (max(diagD) > 1e14 * min(diagD)) {\n                final double tfac = max(diagD) / 1e14 - min(diagD);\n                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n            }\n            diagC = diag(C);\n            diagD = sqrt(diagD); \n            BD = times(B, repmat(diagD.transpose(), dimension, 1)); \n        }\n    }\n\n    \n    private static void push(double[] vals, double val) {\n        for (int i = vals.length-1; i > 0; i--) {\n            vals[i] = vals[i-1];\n        }\n        vals[0] = val;\n    }\n\n    \n    private int[] sortedIndices(final double[] doubles) {\n        final DoubleIndex[] dis = new DoubleIndex[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            dis[i] = new DoubleIndex(doubles[i], i);\n        }\n        Arrays.sort(dis);\n        final int[] indices = new int[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            indices[i] = dis[i].index;\n        }\n        return indices;\n    }\n\n    \n    private static class DoubleIndex implements Comparable<DoubleIndex> { private final double value; private final int index; DoubleIndex(double value, int index) {\n            this.value = value;\n            this.index = index;\n        }\n\n        \n        public int compareTo(DoubleIndex o) {\n            return Double.compare(value, o.value);\n        }\n\n        \n        @Override\n        public boolean equals(Object other) {\n\n            if (this == other) {\n                return true;\n            }\n\n            if (other instanceof DoubleIndex) {\n                return Double.compare(value, ((DoubleIndex) other).value) == 0;\n            }\n\n            return false;\n        }\n\n        \n        @Override\n        public int hashCode() {\n            long bits = Double.doubleToLongBits(value);\n            return (int) ((1438542 ^ (bits >>> 32) ^ bits) & 0xffffffff);\n        }\n    }\n\n    \n    private class FitnessFunction { private double valueRange; private final boolean isRepairMode; public FitnessFunction() {\n            valueRange = 1;\n            isRepairMode = true;\n        }\n\n        \n        public double value(final double[] point) {\n            double value;\n            if (isRepairMode) {\n                double[] repaired = repair(point);\n                value = CMAESOptimizer.this.computeObjectiveValue(repaired) +\n                    penalty(point, repaired);\n            } else {\n                value = CMAESOptimizer.this.computeObjectiveValue(point);\n            }\n            return isMinimize ? value : -value;\n        }\n\n        \n        public boolean isFeasible(final double[] x) {\n            final double[] lB = CMAESOptimizer.this.getLowerBound();\n            final double[] uB = CMAESOptimizer.this.getUpperBound();\n\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < lB[i]) {\n                    return false;\n                }\n                if (x[i] > uB[i]) {\n                    return false;\n                }\n            }\n            return true;\n        }\n\n        \n        public void setValueRange(double valueRange) {\n            this.valueRange = valueRange;\n        }\n\n        \n        private double[] repair(final double[] x) {\n            final double[] lB = CMAESOptimizer.this.getLowerBound();\n            final double[] uB = CMAESOptimizer.this.getUpperBound();\n\n            final double[] repaired = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < lB[i]) {\n                    repaired[i] = lB[i];\n                } else if (x[i] > uB[i]) {\n                    repaired[i] = uB[i];\n                } else {\n                    repaired[i] = x[i];\n                }\n            }\n            return repaired;\n        }\n\n        \n        private double penalty(final double[] x, final double[] repaired) {\n            double penalty = 0;\n            for (int i = 0; i < x.length; i++) {\n                double diff = Math.abs(x[i] - repaired[i]);\n                penalty += diff * valueRange;\n            }\n            return isMinimize ? penalty : -penalty;\n        }\n    }\n\n    \n\n    \n    private static RealMatrix log(final RealMatrix m) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.log(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix sqrt(final RealMatrix m) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.sqrt(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix square(final RealMatrix m) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                d[r][c] = e * e;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix times(final RealMatrix m, final RealMatrix n) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) * n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix divide(final RealMatrix m, final RealMatrix n) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) / n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix selectColumns(final RealMatrix m, final int[] cols) {\n        final double[][] d = new double[m.getRowDimension()][cols.length];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < cols.length; c++) {\n                d[r][c] = m.getEntry(r, cols[c]);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix triu(final RealMatrix m, int k) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = r <= c - k ? m.getEntry(r, c) : 0;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix sumRows(final RealMatrix m) {\n        final double[][] d = new double[1][m.getColumnDimension()];\n        for (int c = 0; c < m.getColumnDimension(); c++) {\n            double sum = 0;\n            for (int r = 0; r < m.getRowDimension(); r++) {\n                sum += m.getEntry(r, c);\n            }\n            d[0][c] = sum;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix diag(final RealMatrix m) {\n        if (m.getColumnDimension() == 1) {\n            final double[][] d = new double[m.getRowDimension()][m.getRowDimension()];\n            for (int i = 0; i < m.getRowDimension(); i++) {\n                d[i][i] = m.getEntry(i, 0);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        } else {\n            final double[][] d = new double[m.getRowDimension()][1];\n            for (int i = 0; i < m.getColumnDimension(); i++) {\n                d[i][0] = m.getEntry(i, i);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        }\n    }\n\n    \n    private static void copyColumn(final RealMatrix m1, int col1, RealMatrix m2, int col2) {\n        for (int i = 0; i < m1.getRowDimension(); i++) {\n            m2.setEntry(i, col2, m1.getEntry(i, col1));\n        }\n    }\n\n    \n    private static RealMatrix ones(int n, int m) {\n        final double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            Arrays.fill(d[r], 1);\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix eye(int n, int m) {\n        final double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            if (r < m) {\n                d[r][r] = 1;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix zeros(int n, int m) {\n        return new Array2DRowRealMatrix(n, m);\n    }\n\n    \n    private static RealMatrix repmat(final RealMatrix mat, int n, int m) {\n        final int rd = mat.getRowDimension();\n        final int cd = mat.getColumnDimension();\n        final double[][] d = new double[n * rd][m * cd];\n        for (int r = 0; r < n * rd; r++) {\n            for (int c = 0; c < m * cd; c++) {\n                d[r][c] = mat.getEntry(r % rd, c % cd);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix sequence(double start, double end, double step) {\n        final int size = (int) ((end - start) / step + 1);\n        final double[][] d = new double[size][1];\n        double value = start;\n        for (int r = 0; r < size; r++) {\n            d[r][0] = value;\n            value += step;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static double max(final RealMatrix m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                if (max < e) {\n                    max = e;\n                }\n            }\n        }\n        return max;\n    }\n\n    \n    private static double min(final RealMatrix m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                if (min > e) {\n                    min = e;\n                }\n            }\n        }\n        return min;\n    }\n\n    \n    private static double max(final double[] m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (max < m[r]) {\n                max = m[r];\n            }\n        }\n        return max;\n    }\n\n    \n    private static double min(final double[] m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (min > m[r]) {\n                min = m[r];\n            }\n        }\n        return min;\n    }\n\n    \n    private static int[] inverse(final int[] indices) {\n        final int[] inverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            inverse[indices[i]] = i;\n        }\n        return inverse;\n    }\n\n    \n    private static int[] reverse(final int[] indices) {\n        final int[] reverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            reverse[i] = indices[indices.length - i - 1];\n        }\n        return reverse;\n    }\n\n    \n    private double[] randn(int size) {\n        final double[] randn = new double[size];\n        for (int i = 0; i < size; i++) {\n            randn[i] = random.nextGaussian();\n        }\n        return randn;\n    }\n\n    \n    private RealMatrix randn1(int size, int popSize) {\n        final double[][] d = new double[size][popSize];\n        for (int r = 0; r < size; r++) {\n            for (int c = 0; c < popSize; c++) {\n                d[r][c] = random.nextGaussian();\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n}\n",
      "fixed_full_code": "\n\npackage org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport org.apache.commons.math3.exception.DimensionMismatchException;\nimport org.apache.commons.math3.exception.NotPositiveException;\nimport org.apache.commons.math3.exception.NotStrictlyPositiveException;\nimport org.apache.commons.math3.exception.OutOfRangeException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.linear.Array2DRowRealMatrix;\nimport org.apache.commons.math3.linear.EigenDecomposition;\nimport org.apache.commons.math3.linear.MatrixUtils;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\nimport org.apache.commons.math3.random.RandomGenerator;\nimport org.apache.commons.math3.util.MathArrays;\n\n\npublic class CMAESOptimizer extends MultivariateOptimizer { private int lambda; private final boolean isActiveCMA; private final int checkFeasableCount; private double[] inputSigma; private int dimension; private int diagonalOnly; private boolean isMinimize = true; private final boolean generateStatistics; private final int maxIterations; private final double stopFitness; private double stopTolUpX; private double stopTolX; private double stopTolFun; private double stopTolHistFun; private int mu; private double logMu2; private RealMatrix weights; private double mueff; private double sigma; private double cc; private double cs; private double damps; private double ccov1; private double ccovmu; private double chiN; private double ccov1Sep; private double ccovmuSep; private RealMatrix xmean; private RealMatrix pc; private RealMatrix ps; private double normps; private RealMatrix B; private RealMatrix D; private RealMatrix BD; private RealMatrix diagD; private RealMatrix C; private RealMatrix diagC; private int iterations; private double[] fitnessHistory; private int historySize; private final RandomGenerator random; private final List<Double> statisticsSigmaHistory = new ArrayList<Double>(); private final List<RealMatrix> statisticsMeanHistory = new ArrayList<RealMatrix>(); private final List<Double> statisticsFitnessHistory = new ArrayList<Double>(); private final List<RealMatrix> statisticsDHistory = new ArrayList<RealMatrix>(); public CMAESOptimizer(int maxIterations, double stopFitness, boolean isActiveCMA, int diagonalOnly, int checkFeasableCount, RandomGenerator random, boolean generateStatistics, ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n        this.maxIterations = maxIterations;\n        this.stopFitness = stopFitness;\n        this.isActiveCMA = isActiveCMA;\n        this.diagonalOnly = diagonalOnly;\n        this.checkFeasableCount = checkFeasableCount;\n        this.random = random;\n        this.generateStatistics = generateStatistics;\n    }\n\n    \n    public List<Double> getStatisticsSigmaHistory() {\n        return statisticsSigmaHistory;\n    }\n\n    \n    public List<RealMatrix> getStatisticsMeanHistory() {\n        return statisticsMeanHistory;\n    }\n\n    \n    public List<Double> getStatisticsFitnessHistory() {\n        return statisticsFitnessHistory;\n    }\n\n    \n    public List<RealMatrix> getStatisticsDHistory() {\n        return statisticsDHistory;\n    }\n\n    \n    public static class Sigma implements OptimizationData { private final double[] sigma; public Sigma(double[] s) throws NotPositiveException {\n            for (int i = 0; i < s.length; i++) {\n                if (s[i] < 0) {\n                    throw new NotPositiveException(s[i]);\n                }\n            }\n\n            sigma = s.clone();\n        }\n\n        \n        public double[] getSigma() {\n            return sigma.clone();\n        }\n    }\n\n    \n    public static class PopulationSize implements OptimizationData { private final int lambda; public PopulationSize(int size) throws NotStrictlyPositiveException {\n            if (size <= 0) {\n                throw new NotStrictlyPositiveException(size);\n            }\n            lambda = size;\n        }\n\n        \n        public int getPopulationSize() {\n            return lambda;\n        }\n    }\n\n    \n    @Override\n    public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException, DimensionMismatchException {\n        \n        return super.optimize(optData);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n         \n        isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n        final FitnessFunction fitfun = new FitnessFunction();\n        final double[] guess = getStartPoint();\n        \n        dimension = guess.length;\n        initializeCMA(guess);\n        iterations = 0;\n        double bestValue = fitfun.value(guess);\n        push(fitnessHistory, bestValue);\n        PointValuePair optimum\n            = new PointValuePair(getStartPoint(),\n                                 isMinimize ? bestValue : -bestValue);\n        PointValuePair lastResult = null;\n\n        \n\n        generationLoop:\n        for (iterations = 1; iterations <= maxIterations; iterations++) {\n            incrementIterationCount();\n\n            \n            final RealMatrix arz = randn1(dimension, lambda);\n            final RealMatrix arx = zeros(dimension, lambda);\n            final double[] fitness = new double[lambda];\n            \n            for (int k = 0; k < lambda; k++) {\n                RealMatrix arxk = null;\n                for (int i = 0; i < checkFeasableCount + 1; i++) {\n                    if (diagonalOnly <= 0) {\n                        arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n                                         .scalarMultiply(sigma)); \n                    } else {\n                        arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n                                         .scalarMultiply(sigma));\n                    }\n                    if (i >= checkFeasableCount ||\n                        fitfun.isFeasible(arxk.getColumn(0))) {\n                        break;\n                    }\n                    \n                    arz.setColumn(k, randn(dimension));\n                }\n                copyColumn(arxk, 0, arx, k);\n                try {\n                    fitness[k] = fitfun.value(arx.getColumn(k)); \n                } catch (TooManyEvaluationsException e) {\n                    break generationLoop;\n                }\n            }\n            \n            final int[] arindex = sortedIndices(fitness);\n            \n            final RealMatrix xold = xmean; \n            final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n            xmean = bestArx.multiply(weights);\n            final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n            final RealMatrix zmean = bestArz.multiply(weights);\n            final boolean hsig = updateEvolutionPaths(zmean, xold);\n            if (diagonalOnly <= 0) {\n                updateCovariance(hsig, bestArx, arz, arindex, xold);\n            } else {\n                updateCovarianceDiagonalOnly(hsig, bestArz);\n            }\n            \n            sigma *= Math.exp(Math.min(1, (normps/chiN - 1) * cs / damps));\n            final double bestFitness = fitness[arindex[0]];\n            final double worstFitness = fitness[arindex[arindex.length - 1]];\n            if (bestValue > bestFitness) {\n                bestValue = bestFitness;\n                lastResult = optimum;\n                optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)),\n                                             isMinimize ? bestFitness : -bestFitness);\n                if (getConvergenceChecker() != null &&\n                    lastResult != null) {\n                    if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n                        break generationLoop;\n                    }\n                }\n            }\n            \n            \n            if (stopFitness != 0) { \n                if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n                    break generationLoop;\n                }\n            }\n            final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n            final double[] pcCol = pc.getColumn(0);\n            for (int i = 0; i < dimension; i++) {\n                if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n                    break;\n                }\n                if (i >= dimension - 1) {\n                    break generationLoop;\n                }\n            }\n            for (int i = 0; i < dimension; i++) {\n                if (sigma * sqrtDiagC[i] > stopTolUpX) {\n                    break generationLoop;\n                }\n            }\n            final double historyBest = min(fitnessHistory);\n            final double historyWorst = max(fitnessHistory);\n            if (iterations > 2 &&\n                Math.max(historyWorst, worstFitness) -\n                Math.min(historyBest, bestFitness) < stopTolFun) {\n                break generationLoop;\n            }\n            if (iterations > fitnessHistory.length &&\n                historyWorst - historyBest < stopTolHistFun) {\n                break generationLoop;\n            }\n            \n            if (max(diagD) / min(diagD) > 1e7) {\n                break generationLoop;\n            }\n            \n            if (getConvergenceChecker() != null) {\n                final PointValuePair current\n                    = new PointValuePair(bestArx.getColumn(0),\n                                         isMinimize ? bestFitness : -bestFitness);\n                if (lastResult != null &&\n                    getConvergenceChecker().converged(iterations, current, lastResult)) {\n                    break generationLoop;\n                    }\n                lastResult = current;\n            }\n            \n            if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n                sigma = sigma * Math.exp(0.2 + cs / damps);\n            }\n            if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n                Math.min(historyBest, bestFitness) == 0) {\n                sigma = sigma * Math.exp(0.2 + cs / damps);\n            }\n            \n            push(fitnessHistory,bestFitness);\n            fitfun.setValueRange(worstFitness-bestFitness);\n            if (generateStatistics) {\n                statisticsSigmaHistory.add(sigma);\n                statisticsFitnessHistory.add(bestFitness);\n                statisticsMeanHistory.add(xmean.transpose());\n                statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n            }\n        }\n        return optimum;\n    }\n\n    \n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        super.parseOptimizationData(optData);\n\n        \n        \n        for (OptimizationData data : optData) {\n            if (data instanceof Sigma) {\n                inputSigma = ((Sigma) data).getSigma();\n                continue;\n            }\n            if (data instanceof PopulationSize) {\n                lambda = ((PopulationSize) data).getPopulationSize();\n                continue;\n            }\n        }\n\n        checkParameters();\n    }\n\n    \n    private void checkParameters() {\n        final double[] init = getStartPoint();\n        final double[] lB = getLowerBound();\n        final double[] uB = getUpperBound();\n\n        if (inputSigma != null) {\n            if (inputSigma.length != init.length) {\n                throw new DimensionMismatchException(inputSigma.length, init.length);\n            }\n            for (int i = 0; i < init.length; i++) {\n                if (inputSigma[i] > uB[i] - lB[i]) {\n                    throw new OutOfRangeException(inputSigma[i], 0, uB[i] - lB[i]);\n                }\n            }\n        }\n    }\n\n    \n    private void initializeCMA(double[] guess) {\n        if (lambda <= 0) {\n            throw new NotStrictlyPositiveException(lambda);\n        }\n        \n        final double[][] sigmaArray = new double[guess.length][1];\n        for (int i = 0; i < guess.length; i++) {\n            sigmaArray[i][0] = inputSigma[i];\n        }\n        final RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);\n        sigma = max(insigma); \n\n        \n        stopTolUpX = 1e3 * max(insigma);\n        stopTolX = 1e-11 * max(insigma);\n        stopTolFun = 1e-12;\n        stopTolHistFun = 1e-13;\n\n        \n        mu = lambda / 2; \n        logMu2 = Math.log(mu + 0.5);\n        weights = log(sequence(1, mu, 1)).scalarMultiply(-1).scalarAdd(logMu2);\n        double sumw = 0;\n        double sumwq = 0;\n        for (int i = 0; i < mu; i++) {\n            double w = weights.getEntry(i, 0);\n            sumw += w;\n            sumwq += w * w;\n        }\n        weights = weights.scalarMultiply(1 / sumw);\n        mueff = sumw * sumw / sumwq; \n\n        \n        cc = (4 + mueff / dimension) /\n                (dimension + 4 + 2 * mueff / dimension);\n        cs = (mueff + 2) / (dimension + mueff + 3.);\n        damps = (1 + 2 * Math.max(0, Math.sqrt((mueff - 1) /\n                                               (dimension + 1)) - 1)) *\n            Math.max(0.3,\n                     1 - dimension / (1e-6 + maxIterations)) + cs; \n        ccov1 = 2 / ((dimension + 1.3) * (dimension + 1.3) + mueff);\n        ccovmu = Math.min(1 - ccov1, 2 * (mueff - 2 + 1 / mueff) /\n                          ((dimension + 2) * (dimension + 2) + mueff));\n        ccov1Sep = Math.min(1, ccov1 * (dimension + 1.5) / 3);\n        ccovmuSep = Math.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3);\n        chiN = Math.sqrt(dimension) *\n            (1 - 1 / ((double) 4 * dimension) + 1 / ((double) 21 * dimension * dimension));\n        \n        xmean = MatrixUtils.createColumnRealMatrix(guess); \n        diagD = insigma.scalarMultiply(1 / sigma);\n        diagC = square(diagD);\n        pc = zeros(dimension, 1); \n        ps = zeros(dimension, 1); \n        normps = ps.getFrobeniusNorm();\n\n        B = eye(dimension, dimension);\n        D = ones(dimension, 1); \n        BD = times(B, repmat(diagD.transpose(), dimension, 1));\n        C = B.multiply(diag(square(D)).multiply(B.transpose())); \n        historySize = 10 + (int) (3 * 10 * dimension / (double) lambda);\n        fitnessHistory = new double[historySize]; \n        for (int i = 0; i < historySize; i++) {\n            fitnessHistory[i] = Double.MAX_VALUE;\n        }\n    }\n\n    \n    private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold) {\n        ps = ps.scalarMultiply(1 - cs).add(\n                B.multiply(zmean).scalarMultiply(\n                        Math.sqrt(cs * (2 - cs) * mueff)));\n        normps = ps.getFrobeniusNorm();\n        final boolean hsig = normps /\n            Math.sqrt(1 - Math.pow(1 - cs, 2 * iterations)) /\n            chiN < 1.4 + 2 / ((double) dimension + 1);\n        pc = pc.scalarMultiply(1 - cc);\n        if (hsig) {\n            pc = pc.add(xmean.subtract(xold).scalarMultiply(Math.sqrt(cc * (2 - cc) * mueff) / sigma));\n        }\n        return hsig;\n    }\n\n    \n    private void updateCovarianceDiagonalOnly(boolean hsig, final RealMatrix bestArz) {\n        \n        double oldFac = hsig ? 0 : ccov1Sep * cc * (2 - cc);\n        oldFac += 1 - ccov1Sep - ccovmuSep;\n        diagC = diagC.scalarMultiply(oldFac) \n            .add(square(pc).scalarMultiply(ccov1Sep)) \n            .add((times(diagC, square(bestArz).multiply(weights))) \n                 .scalarMultiply(ccovmuSep));\n        diagD = sqrt(diagC); \n        if (diagonalOnly > 1 &&\n            iterations > diagonalOnly) {\n            \n            diagonalOnly = 0;\n            B = eye(dimension, dimension);\n            BD = diag(diagD);\n            C = diag(diagC);\n        }\n    }\n\n    \n    private void updateCovariance(boolean hsig, final RealMatrix bestArx, final RealMatrix arz, final int[] arindex, final RealMatrix xold) {\n        double negccov = 0;\n        if (ccov1 + ccovmu > 0) {\n            final RealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))\n                .scalarMultiply(1 / sigma); \n            final RealMatrix roneu = pc.multiply(pc.transpose())\n                .scalarMultiply(ccov1); \n            \n            double oldFac = hsig ? 0 : ccov1 * cc * (2 - cc);\n            oldFac += 1 - ccov1 - ccovmu;\n            if (isActiveCMA) {\n                \n                negccov = (1 - ccovmu) * 0.25 * mueff /\n                    (Math.pow(dimension + 2, 1.5) + 2 * mueff);\n                \n                \n                final double negminresidualvariance = 0.66;\n                \n                final double negalphaold = 0.5;\n                \n                final int[] arReverseIndex = reverse(arindex);\n                RealMatrix arzneg = selectColumns(arz, MathArrays.copyOf(arReverseIndex, mu));\n                RealMatrix arnorms = sqrt(sumRows(square(arzneg)));\n                final int[] idxnorms = sortedIndices(arnorms.getRow(0));\n                final RealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);\n                final int[] idxReverse = reverse(idxnorms);\n                final RealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);\n                arnorms = divide(arnormsReverse, arnormsSorted);\n                final int[] idxInv = inverse(idxnorms);\n                final RealMatrix arnormsInv = selectColumns(arnorms, idxInv);\n                \n                final double negcovMax = (1 - negminresidualvariance) /\n                    square(arnormsInv).multiply(weights).getEntry(0, 0);\n                if (negccov > negcovMax) {\n                    negccov = negcovMax;\n                }\n                arzneg = times(arzneg, repmat(arnormsInv, dimension, 1));\n                final RealMatrix artmp = BD.multiply(arzneg);\n                final RealMatrix Cneg = artmp.multiply(diag(weights)).multiply(artmp.transpose());\n                oldFac += negalphaold * negccov;\n                C = C.scalarMultiply(oldFac)\n                    .add(roneu) \n                    .add(arpos.scalarMultiply( \n                                              ccovmu + (1 - negalphaold) * negccov) \n                         .multiply(times(repmat(weights, 1, dimension),\n                                         arpos.transpose())))\n                    .subtract(Cneg.scalarMultiply(negccov));\n            } else {\n                \n                C = C.scalarMultiply(oldFac) \n                    .add(roneu) \n                    .add(arpos.scalarMultiply(ccovmu) \n                         .multiply(times(repmat(weights, 1, dimension),\n                                         arpos.transpose())));\n            }\n        }\n        updateBD(negccov);\n    }\n\n    \n    private void updateBD(double negccov) {\n        if (ccov1 + ccovmu + negccov > 0 &&\n            (iterations % 1. / (ccov1 + ccovmu + negccov) / dimension / 10.) < 1) {\n            \n            C = triu(C, 0).add(triu(C, 1).transpose());\n            \n            final EigenDecomposition eig = new EigenDecomposition(C);\n            B = eig.getV(); \n            D = eig.getD();\n            diagD = diag(D);\n            if (min(diagD) <= 0) {\n                for (int i = 0; i < dimension; i++) {\n                    if (diagD.getEntry(i, 0) < 0) {\n                        diagD.setEntry(i, 0, 0);\n                    }\n                }\n                final double tfac = max(diagD) / 1e14;\n                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n            }\n            if (max(diagD) > 1e14 * min(diagD)) {\n                final double tfac = max(diagD) / 1e14 - min(diagD);\n                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n            }\n            diagC = diag(C);\n            diagD = sqrt(diagD); \n            BD = times(B, repmat(diagD.transpose(), dimension, 1)); \n        }\n    }\n\n    \n    private static void push(double[] vals, double val) {\n        for (int i = vals.length-1; i > 0; i--) {\n            vals[i] = vals[i-1];\n        }\n        vals[0] = val;\n    }\n\n    \n    private int[] sortedIndices(final double[] doubles) {\n        final DoubleIndex[] dis = new DoubleIndex[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            dis[i] = new DoubleIndex(doubles[i], i);\n        }\n        Arrays.sort(dis);\n        final int[] indices = new int[doubles.length];\n        for (int i = 0; i < doubles.length; i++) {\n            indices[i] = dis[i].index;\n        }\n        return indices;\n    }\n\n    \n    private static class DoubleIndex implements Comparable<DoubleIndex> { private final double value; private final int index; DoubleIndex(double value, int index) {\n            this.value = value;\n            this.index = index;\n        }\n\n        \n        public int compareTo(DoubleIndex o) {\n            return Double.compare(value, o.value);\n        }\n\n        \n        @Override\n        public boolean equals(Object other) {\n\n            if (this == other) {\n                return true;\n            }\n\n            if (other instanceof DoubleIndex) {\n                return Double.compare(value, ((DoubleIndex) other).value) == 0;\n            }\n\n            return false;\n        }\n\n        \n        @Override\n        public int hashCode() {\n            long bits = Double.doubleToLongBits(value);\n            return (int) ((1438542 ^ (bits >>> 32) ^ bits) & 0xffffffff);\n        }\n    }\n\n    \n    private class FitnessFunction { private double valueRange; private final boolean isRepairMode; public FitnessFunction() {\n            valueRange = 1;\n            isRepairMode = true;\n        }\n\n        \n        public double value(final double[] point) {\n            double value;\n            if (isRepairMode) {\n                double[] repaired = repair(point);\n                value = CMAESOptimizer.this.computeObjectiveValue(repaired) +\n                    penalty(point, repaired);\n            } else {\n                value = CMAESOptimizer.this.computeObjectiveValue(point);\n            }\n            return isMinimize ? value : -value;\n        }\n\n        \n        public boolean isFeasible(final double[] x) {\n            final double[] lB = CMAESOptimizer.this.getLowerBound();\n            final double[] uB = CMAESOptimizer.this.getUpperBound();\n\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < lB[i]) {\n                    return false;\n                }\n                if (x[i] > uB[i]) {\n                    return false;\n                }\n            }\n            return true;\n        }\n\n        \n        public void setValueRange(double valueRange) {\n            this.valueRange = valueRange;\n        }\n\n        \n        private double[] repair(final double[] x) {\n            final double[] lB = CMAESOptimizer.this.getLowerBound();\n            final double[] uB = CMAESOptimizer.this.getUpperBound();\n\n            final double[] repaired = new double[x.length];\n            for (int i = 0; i < x.length; i++) {\n                if (x[i] < lB[i]) {\n                    repaired[i] = lB[i];\n                } else if (x[i] > uB[i]) {\n                    repaired[i] = uB[i];\n                } else {\n                    repaired[i] = x[i];\n                }\n            }\n            return repaired;\n        }\n\n        \n        private double penalty(final double[] x, final double[] repaired) {\n            double penalty = 0;\n            for (int i = 0; i < x.length; i++) {\n                double diff = Math.abs(x[i] - repaired[i]);\n                penalty += diff * valueRange;\n            }\n            return isMinimize ? penalty : -penalty;\n        }\n    }\n\n    \n\n    \n    private static RealMatrix log(final RealMatrix m) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.log(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix sqrt(final RealMatrix m) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = Math.sqrt(m.getEntry(r, c));\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix square(final RealMatrix m) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                d[r][c] = e * e;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix times(final RealMatrix m, final RealMatrix n) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) * n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix divide(final RealMatrix m, final RealMatrix n) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = m.getEntry(r, c) / n.getEntry(r, c);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix selectColumns(final RealMatrix m, final int[] cols) {\n        final double[][] d = new double[m.getRowDimension()][cols.length];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < cols.length; c++) {\n                d[r][c] = m.getEntry(r, cols[c]);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix triu(final RealMatrix m, int k) {\n        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                d[r][c] = r <= c - k ? m.getEntry(r, c) : 0;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix sumRows(final RealMatrix m) {\n        final double[][] d = new double[1][m.getColumnDimension()];\n        for (int c = 0; c < m.getColumnDimension(); c++) {\n            double sum = 0;\n            for (int r = 0; r < m.getRowDimension(); r++) {\n                sum += m.getEntry(r, c);\n            }\n            d[0][c] = sum;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix diag(final RealMatrix m) {\n        if (m.getColumnDimension() == 1) {\n            final double[][] d = new double[m.getRowDimension()][m.getRowDimension()];\n            for (int i = 0; i < m.getRowDimension(); i++) {\n                d[i][i] = m.getEntry(i, 0);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        } else {\n            final double[][] d = new double[m.getRowDimension()][1];\n            for (int i = 0; i < m.getColumnDimension(); i++) {\n                d[i][0] = m.getEntry(i, i);\n            }\n            return new Array2DRowRealMatrix(d, false);\n        }\n    }\n\n    \n    private static void copyColumn(final RealMatrix m1, int col1, RealMatrix m2, int col2) {\n        for (int i = 0; i < m1.getRowDimension(); i++) {\n            m2.setEntry(i, col2, m1.getEntry(i, col1));\n        }\n    }\n\n    \n    private static RealMatrix ones(int n, int m) {\n        final double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            Arrays.fill(d[r], 1);\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix eye(int n, int m) {\n        final double[][] d = new double[n][m];\n        for (int r = 0; r < n; r++) {\n            if (r < m) {\n                d[r][r] = 1;\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix zeros(int n, int m) {\n        return new Array2DRowRealMatrix(n, m);\n    }\n\n    \n    private static RealMatrix repmat(final RealMatrix mat, int n, int m) {\n        final int rd = mat.getRowDimension();\n        final int cd = mat.getColumnDimension();\n        final double[][] d = new double[n * rd][m * cd];\n        for (int r = 0; r < n * rd; r++) {\n            for (int c = 0; c < m * cd; c++) {\n                d[r][c] = mat.getEntry(r % rd, c % cd);\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static RealMatrix sequence(double start, double end, double step) {\n        final int size = (int) ((end - start) / step + 1);\n        final double[][] d = new double[size][1];\n        double value = start;\n        for (int r = 0; r < size; r++) {\n            d[r][0] = value;\n            value += step;\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n\n    \n    private static double max(final RealMatrix m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                if (max < e) {\n                    max = e;\n                }\n            }\n        }\n        return max;\n    }\n\n    \n    private static double min(final RealMatrix m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.getRowDimension(); r++) {\n            for (int c = 0; c < m.getColumnDimension(); c++) {\n                double e = m.getEntry(r, c);\n                if (min > e) {\n                    min = e;\n                }\n            }\n        }\n        return min;\n    }\n\n    \n    private static double max(final double[] m) {\n        double max = -Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (max < m[r]) {\n                max = m[r];\n            }\n        }\n        return max;\n    }\n\n    \n    private static double min(final double[] m) {\n        double min = Double.MAX_VALUE;\n        for (int r = 0; r < m.length; r++) {\n            if (min > m[r]) {\n                min = m[r];\n            }\n        }\n        return min;\n    }\n\n    \n    private static int[] inverse(final int[] indices) {\n        final int[] inverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            inverse[indices[i]] = i;\n        }\n        return inverse;\n    }\n\n    \n    private static int[] reverse(final int[] indices) {\n        final int[] reverse = new int[indices.length];\n        for (int i = 0; i < indices.length; i++) {\n            reverse[i] = indices[indices.length - i - 1];\n        }\n        return reverse;\n    }\n\n    \n    private double[] randn(int size) {\n        final double[] randn = new double[size];\n        for (int i = 0; i < size; i++) {\n            randn[i] = random.nextGaussian();\n        }\n        return randn;\n    }\n\n    \n    private RealMatrix randn1(int size, int popSize) {\n        final double[][] d = new double[size][popSize];\n        for (int r = 0; r < size; r++) {\n            for (int c = 0; c < popSize; c++) {\n                d[r][c] = random.nextGaussian();\n            }\n        }\n        return new Array2DRowRealMatrix(d, false);\n    }\n}\n",
      "buggy_signatures": [
        "public List<Double> getStatisticsSigmaHistory()",
        "public List<RealMatrix> getStatisticsMeanHistory()",
        "public List<Double> getStatisticsFitnessHistory()",
        "public List<RealMatrix> getStatisticsDHistory()",
        "public static class Sigma implements OptimizationData { private final double[] sigma; public Sigma(double[] s) throws NotPositiveException",
        "public double[] getSigma()",
        "public static class PopulationSize implements OptimizationData { private final int lambda; public PopulationSize(int size) throws NotStrictlyPositiveException",
        "public int getPopulationSize()",
        "public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException, DimensionMismatchException",
        "protected PointValuePair doOptimize()",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private void checkParameters()",
        "private void initializeCMA(double[] guess)",
        "private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold)",
        "private void updateCovarianceDiagonalOnly(boolean hsig, final RealMatrix bestArz)",
        "private void updateCovariance(boolean hsig, final RealMatrix bestArx, final RealMatrix arz, final int[] arindex, final RealMatrix xold)",
        "private void updateBD(double negccov)",
        "private static void push(double[] vals, double val)",
        "private int[] sortedIndices(final double[] doubles)",
        "private static class DoubleIndex implements Comparable<DoubleIndex> { private final double value; private final int index; DoubleIndex(double value, int index)",
        "public int compareTo(DoubleIndex o)",
        "public boolean equals(Object other)",
        "public int hashCode()",
        "private class FitnessFunction { private double valueRange; private final boolean isRepairMode; public FitnessFunction()",
        "public double value(final double[] point)",
        "public boolean isFeasible(final double[] x)",
        "public void setValueRange(double valueRange)",
        "private double[] repair(final double[] x)",
        "private double penalty(final double[] x, final double[] repaired)",
        "private static RealMatrix log(final RealMatrix m)",
        "private static RealMatrix sqrt(final RealMatrix m)",
        "private static RealMatrix square(final RealMatrix m)",
        "private static RealMatrix times(final RealMatrix m, final RealMatrix n)",
        "private static RealMatrix divide(final RealMatrix m, final RealMatrix n)",
        "private static RealMatrix selectColumns(final RealMatrix m, final int[] cols)",
        "private static RealMatrix triu(final RealMatrix m, int k)",
        "private static RealMatrix sumRows(final RealMatrix m)",
        "private static RealMatrix diag(final RealMatrix m)",
        "private static void copyColumn(final RealMatrix m1, int col1, RealMatrix m2, int col2)",
        "private static RealMatrix ones(int n, int m)",
        "private static RealMatrix eye(int n, int m)",
        "private static RealMatrix zeros(int n, int m)",
        "private static RealMatrix repmat(final RealMatrix mat, int n, int m)",
        "private static RealMatrix sequence(double start, double end, double step)",
        "private static double max(final RealMatrix m)",
        "private static double min(final RealMatrix m)",
        "private static double max(final double[] m)",
        "private static double min(final double[] m)",
        "private static int[] inverse(final int[] indices)",
        "private static int[] reverse(final int[] indices)",
        "private double[] randn(int size)",
        "private RealMatrix randn1(int size, int popSize)"
      ],
      "fixed_signatures": [
        "public List<Double> getStatisticsSigmaHistory()",
        "public List<RealMatrix> getStatisticsMeanHistory()",
        "public List<Double> getStatisticsFitnessHistory()",
        "public List<RealMatrix> getStatisticsDHistory()",
        "public static class Sigma implements OptimizationData { private final double[] sigma; public Sigma(double[] s) throws NotPositiveException",
        "public double[] getSigma()",
        "public static class PopulationSize implements OptimizationData { private final int lambda; public PopulationSize(int size) throws NotStrictlyPositiveException",
        "public int getPopulationSize()",
        "public PointValuePair optimize(OptimizationData... optData) throws TooManyEvaluationsException, DimensionMismatchException",
        "protected PointValuePair doOptimize()",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private void checkParameters()",
        "private void initializeCMA(double[] guess)",
        "private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold)",
        "private void updateCovarianceDiagonalOnly(boolean hsig, final RealMatrix bestArz)",
        "private void updateCovariance(boolean hsig, final RealMatrix bestArx, final RealMatrix arz, final int[] arindex, final RealMatrix xold)",
        "private void updateBD(double negccov)",
        "private static void push(double[] vals, double val)",
        "private int[] sortedIndices(final double[] doubles)",
        "private static class DoubleIndex implements Comparable<DoubleIndex> { private final double value; private final int index; DoubleIndex(double value, int index)",
        "public int compareTo(DoubleIndex o)",
        "public boolean equals(Object other)",
        "public int hashCode()",
        "private class FitnessFunction { private double valueRange; private final boolean isRepairMode; public FitnessFunction()",
        "public double value(final double[] point)",
        "public boolean isFeasible(final double[] x)",
        "public void setValueRange(double valueRange)",
        "private double[] repair(final double[] x)",
        "private double penalty(final double[] x, final double[] repaired)",
        "private static RealMatrix log(final RealMatrix m)",
        "private static RealMatrix sqrt(final RealMatrix m)",
        "private static RealMatrix square(final RealMatrix m)",
        "private static RealMatrix times(final RealMatrix m, final RealMatrix n)",
        "private static RealMatrix divide(final RealMatrix m, final RealMatrix n)",
        "private static RealMatrix selectColumns(final RealMatrix m, final int[] cols)",
        "private static RealMatrix triu(final RealMatrix m, int k)",
        "private static RealMatrix sumRows(final RealMatrix m)",
        "private static RealMatrix diag(final RealMatrix m)",
        "private static void copyColumn(final RealMatrix m1, int col1, RealMatrix m2, int col2)",
        "private static RealMatrix ones(int n, int m)",
        "private static RealMatrix eye(int n, int m)",
        "private static RealMatrix zeros(int n, int m)",
        "private static RealMatrix repmat(final RealMatrix mat, int n, int m)",
        "private static RealMatrix sequence(double start, double end, double step)",
        "private static double max(final RealMatrix m)",
        "private static double min(final RealMatrix m)",
        "private static double max(final double[] m)",
        "private static double min(final double[] m)",
        "private static int[] inverse(final int[] indices)",
        "private static int[] reverse(final int[] indices)",
        "private double[] randn(int size)",
        "private RealMatrix randn1(int size, int popSize)"
      ],
      "methods": [
        {
          "buggy_method": "  protected PointValuePair doOptimize() {\n  \n  isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n  final FitnessFunction fitfun = new FitnessFunction();\n  final double[] guess = getStartPoint();\n  \n  dimension = guess.length;\n  initializeCMA(guess);\n  iterations = 0;\n  double bestValue = fitfun.value(guess);\n  push(fitnessHistory, bestValue);\n  PointValuePair optimum\n  = new PointValuePair(getStartPoint(),\n  isMinimize ? bestValue : -bestValue);\n  PointValuePair lastResult = null;\n\n  \n\n  generationLoop:\n  for (iterations = 1; iterations <= maxIterations; iterations++) {\n\n  \n  final RealMatrix arz = randn1(dimension, lambda);\n  final RealMatrix arx = zeros(dimension, lambda);\n  final double[] fitness = new double[lambda];\n  \n  for (int k = 0; k < lambda; k++) {\n  RealMatrix arxk = null;\n  for (int i = 0; i < checkFeasableCount + 1; i++) {\n  if (diagonalOnly <= 0) {\n  arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n  .scalarMultiply(sigma)); \n  } else {\n  arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n  .scalarMultiply(sigma));\n  }\n  if (i >= checkFeasableCount ||\n  fitfun.isFeasible(arxk.getColumn(0))) {\n  break;\n  }\n  \n  arz.setColumn(k, randn(dimension));\n  }\n  copyColumn(arxk, 0, arx, k);\n  try {\n  fitness[k] = fitfun.value(arx.getColumn(k)); \n  } catch (TooManyEvaluationsException e) {\n  break generationLoop;\n  }\n  }\n  \n  final int[] arindex = sortedIndices(fitness);\n  \n  final RealMatrix xold = xmean; \n  final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n  xmean = bestArx.multiply(weights);\n  final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n  final RealMatrix zmean = bestArz.multiply(weights);\n  final boolean hsig = updateEvolutionPaths(zmean, xold);\n  if (diagonalOnly <= 0) {\n  updateCovariance(hsig, bestArx, arz, arindex, xold);\n  } else {\n  updateCovarianceDiagonalOnly(hsig, bestArz);\n  }\n  \n  sigma *= Math.exp(Math.min(1, (normps/chiN - 1) * cs / damps));\n  final double bestFitness = fitness[arindex[0]];\n  final double worstFitness = fitness[arindex[arindex.length - 1]];\n  if (bestValue > bestFitness) {\n  bestValue = bestFitness;\n  lastResult = optimum;\n  optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)),\n  isMinimize ? bestFitness : -bestFitness);\n  if (getConvergenceChecker() != null &&\n  lastResult != null) {\n  if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n  break generationLoop;\n  }\n  }\n  }\n  \n  \n  if (stopFitness != 0) { \n  if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n  break generationLoop;\n  }\n  }\n  final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n  final double[] pcCol = pc.getColumn(0);\n  for (int i = 0; i < dimension; i++) {\n  if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n  break;\n  }\n  if (i >= dimension - 1) {\n  break generationLoop;\n  }\n  }\n  for (int i = 0; i < dimension; i++) {\n  if (sigma * sqrtDiagC[i] > stopTolUpX) {\n  break generationLoop;\n  }\n  }\n  final double historyBest = min(fitnessHistory);\n  final double historyWorst = max(fitnessHistory);\n  if (iterations > 2 &&\n  Math.max(historyWorst, worstFitness) -\n  Math.min(historyBest, bestFitness) < stopTolFun) {\n  break generationLoop;\n  }\n  if (iterations > fitnessHistory.length &&\n  historyWorst - historyBest < stopTolHistFun) {\n  break generationLoop;\n  }\n  \n  if (max(diagD) / min(diagD) > 1e7) {\n  break generationLoop;\n  }\n  \n  if (getConvergenceChecker() != null) {\n  final PointValuePair current\n  = new PointValuePair(bestArx.getColumn(0),\n  isMinimize ? bestFitness : -bestFitness);\n  if (lastResult != null &&\n  getConvergenceChecker().converged(iterations, current, lastResult)) {\n  break generationLoop;\n  }\n  lastResult = current;\n  }\n  \n  if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n  sigma = sigma * Math.exp(0.2 + cs / damps);\n  }\n  if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n  Math.min(historyBest, bestFitness) == 0) {\n  sigma = sigma * Math.exp(0.2 + cs / damps);\n  }\n  \n  push(fitnessHistory,bestFitness);\n  fitfun.setValueRange(worstFitness-bestFitness);\n  if (generateStatistics) {\n  statisticsSigmaHistory.add(sigma);\n  statisticsFitnessHistory.add(bestFitness);\n  statisticsMeanHistory.add(xmean.transpose());\n  statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n  }\n  }\n  return optimum;\n  }",
          "fixed_method": "  protected PointValuePair doOptimize() {\n  \n  isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n  final FitnessFunction fitfun = new FitnessFunction();\n  final double[] guess = getStartPoint();\n  \n  dimension = guess.length;\n  initializeCMA(guess);\n  iterations = 0;\n  double bestValue = fitfun.value(guess);\n  push(fitnessHistory, bestValue);\n  PointValuePair optimum\n  = new PointValuePair(getStartPoint(),\n  isMinimize ? bestValue : -bestValue);\n  PointValuePair lastResult = null;\n\n  \n\n  generationLoop:\n  for (iterations = 1; iterations <= maxIterations; iterations++) {\n  incrementIterationCount();\n\n  \n  final RealMatrix arz = randn1(dimension, lambda);\n  final RealMatrix arx = zeros(dimension, lambda);\n  final double[] fitness = new double[lambda];\n  \n  for (int k = 0; k < lambda; k++) {\n  RealMatrix arxk = null;\n  for (int i = 0; i < checkFeasableCount + 1; i++) {\n  if (diagonalOnly <= 0) {\n  arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n  .scalarMultiply(sigma)); \n  } else {\n  arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n  .scalarMultiply(sigma));\n  }\n  if (i >= checkFeasableCount ||\n  fitfun.isFeasible(arxk.getColumn(0))) {\n  break;\n  }\n  \n  arz.setColumn(k, randn(dimension));\n  }\n  copyColumn(arxk, 0, arx, k);\n  try {\n  fitness[k] = fitfun.value(arx.getColumn(k)); \n  } catch (TooManyEvaluationsException e) {\n  break generationLoop;\n  }\n  }\n  \n  final int[] arindex = sortedIndices(fitness);\n  \n  final RealMatrix xold = xmean; \n  final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n  xmean = bestArx.multiply(weights);\n  final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n  final RealMatrix zmean = bestArz.multiply(weights);\n  final boolean hsig = updateEvolutionPaths(zmean, xold);\n  if (diagonalOnly <= 0) {\n  updateCovariance(hsig, bestArx, arz, arindex, xold);\n  } else {\n  updateCovarianceDiagonalOnly(hsig, bestArz);\n  }\n  \n  sigma *= Math.exp(Math.min(1, (normps/chiN - 1) * cs / damps));\n  final double bestFitness = fitness[arindex[0]];\n  final double worstFitness = fitness[arindex[arindex.length - 1]];\n  if (bestValue > bestFitness) {\n  bestValue = bestFitness;\n  lastResult = optimum;\n  optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)),\n  isMinimize ? bestFitness : -bestFitness);\n  if (getConvergenceChecker() != null &&\n  lastResult != null) {\n  if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n  break generationLoop;\n  }\n  }\n  }\n  \n  \n  if (stopFitness != 0) { \n  if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n  break generationLoop;\n  }\n  }\n  final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n  final double[] pcCol = pc.getColumn(0);\n  for (int i = 0; i < dimension; i++) {\n  if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n  break;\n  }\n  if (i >= dimension - 1) {\n  break generationLoop;\n  }\n  }\n  for (int i = 0; i < dimension; i++) {\n  if (sigma * sqrtDiagC[i] > stopTolUpX) {\n  break generationLoop;\n  }\n  }\n  final double historyBest = min(fitnessHistory);\n  final double historyWorst = max(fitnessHistory);\n  if (iterations > 2 &&\n  Math.max(historyWorst, worstFitness) -\n  Math.min(historyBest, bestFitness) < stopTolFun) {\n  break generationLoop;\n  }\n  if (iterations > fitnessHistory.length &&\n  historyWorst - historyBest < stopTolHistFun) {\n  break generationLoop;\n  }\n  \n  if (max(diagD) / min(diagD) > 1e7) {\n  break generationLoop;\n  }\n  \n  if (getConvergenceChecker() != null) {\n  final PointValuePair current\n  = new PointValuePair(bestArx.getColumn(0),\n  isMinimize ? bestFitness : -bestFitness);\n  if (lastResult != null &&\n  getConvergenceChecker().converged(iterations, current, lastResult)) {\n  break generationLoop;\n  }\n  lastResult = current;\n  }\n  \n  if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n  sigma = sigma * Math.exp(0.2 + cs / damps);\n  }\n  if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n  Math.min(historyBest, bestFitness) == 0) {\n  sigma = sigma * Math.exp(0.2 + cs / damps);\n  }\n  \n  push(fitnessHistory,bestFitness);\n  fitfun.setValueRange(worstFitness-bestFitness);\n  if (generateStatistics) {\n  statisticsSigmaHistory.add(sigma);\n  statisticsFitnessHistory.add(bestFitness);\n  statisticsMeanHistory.add(xmean.transpose());\n  statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n  }\n  }\n  return optimum;\n  }",
          "diff": [
            "@@ -385,6 +385,7 @@",
            " \n",
            "         generationLoop:\n",
            "         for (iterations = 1; iterations <= maxIterations; iterations++) {\n",
            "+            incrementIterationCount();\n",
            " \n",
            "             // Generate and evaluate lambda offspring\n",
            "             final RealMatrix arz = randn1(dimension, lambda);\n"
          ],
          "changed_lines": 1
        }
      ]
    },
    {
      "name": "org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java",
      "buggy_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n\nimport org.apache.commons.math3.util.FastMath;\nimport org.apache.commons.math3.util.MathArrays;\nimport org.apache.commons.math3.analysis.UnivariateFunction;\nimport org.apache.commons.math3.exception.NumberIsTooSmallException;\nimport org.apache.commons.math3.exception.NotStrictlyPositiveException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.MaxEval;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\nimport org.apache.commons.math3.optim.univariate.BracketFinder;\nimport org.apache.commons.math3.optim.univariate.BrentOptimizer;\nimport org.apache.commons.math3.optim.univariate.UnivariatePointValuePair;\nimport org.apache.commons.math3.optim.univariate.SimpleUnivariateValueChecker;\nimport org.apache.commons.math3.optim.univariate.SearchInterval;\nimport org.apache.commons.math3.optim.univariate.UnivariateObjectiveFunction;\n\n\npublic class PowellOptimizer extends MultivariateOptimizer { private static final double MIN_RELATIVE_TOLERANCE = 2 * FastMath.ulp(1d); private final double relativeThreshold; private final double absoluteThreshold; private final LineSearch line; public PowellOptimizer(double rel, double abs, ConvergenceChecker<PointValuePair> checker) {\n        this(rel, abs, FastMath.sqrt(rel), FastMath.sqrt(abs), checker);\n    }\n\n    \n    public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs, ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n\n        if (rel < MIN_RELATIVE_TOLERANCE) {\n            throw new NumberIsTooSmallException(rel, MIN_RELATIVE_TOLERANCE, true);\n        }\n        if (abs <= 0) {\n            throw new NotStrictlyPositiveException(abs);\n        }\n        relativeThreshold = rel;\n        absoluteThreshold = abs;\n\n        \n        line = new LineSearch(lineRel,\n                              lineAbs);\n    }\n\n    \n    public PowellOptimizer(double rel, double abs) {\n        this(rel, abs, null);\n    }\n\n    \n    public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs) {\n        this(rel, abs, lineRel, lineAbs, null);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n        checkParameters();\n\n        final GoalType goal = getGoalType();\n        final double[] guess = getStartPoint();\n        final int n = guess.length;\n\n        final double[][] direc = new double[n][n];\n        for (int i = 0; i < n; i++) {\n            direc[i][i] = 1;\n        }\n\n        final ConvergenceChecker<PointValuePair> checker\n            = getConvergenceChecker();\n\n        double[] x = guess;\n        double fVal = computeObjectiveValue(x);\n        double[] x1 = x.clone();\n        int iter = 0;\n        while (true) {\n            ++iter;\n\n            double fX = fVal;\n            double fX2 = 0;\n            double delta = 0;\n            int bigInd = 0;\n            double alphaMin = 0;\n\n            for (int i = 0; i < n; i++) {\n                final double[] d = MathArrays.copyOf(direc[i]);\n\n                fX2 = fVal;\n\n                final UnivariatePointValuePair optimum = line.search(x, d);\n                fVal = optimum.getValue();\n                alphaMin = optimum.getPoint();\n                final double[][] result = newPointAndDirection(x, d, alphaMin);\n                x = result[0];\n\n                if ((fX2 - fVal) > delta) {\n                    delta = fX2 - fVal;\n                    bigInd = i;\n                }\n            }\n\n            \n            boolean stop = 2 * (fX - fVal) <=\n                (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) +\n                 absoluteThreshold);\n\n            final PointValuePair previous = new PointValuePair(x1, fX);\n            final PointValuePair current = new PointValuePair(x, fVal);\n            if (!stop) { \n                if (checker != null) {\n                    stop = checker.converged(iter, previous, current);\n                }\n            }\n            if (stop) {\n                if (goal == GoalType.MINIMIZE) {\n                    return (fVal < fX) ? current : previous;\n                } else {\n                    return (fVal > fX) ? current : previous;\n                }\n            }\n\n            final double[] d = new double[n];\n            final double[] x2 = new double[n];\n            for (int i = 0; i < n; i++) {\n                d[i] = x[i] - x1[i];\n                x2[i] = 2 * x[i] - x1[i];\n            }\n\n            x1 = x.clone();\n            fX2 = computeObjectiveValue(x2);\n\n            if (fX > fX2) {\n                double t = 2 * (fX + fX2 - 2 * fVal);\n                double temp = fX - fVal - delta;\n                t *= temp * temp;\n                temp = fX - fX2;\n                t -= delta * temp * temp;\n\n                if (t < 0.0) {\n                    final UnivariatePointValuePair optimum = line.search(x, d);\n                    fVal = optimum.getValue();\n                    alphaMin = optimum.getPoint();\n                    final double[][] result = newPointAndDirection(x, d, alphaMin);\n                    x = result[0];\n\n                    final int lastInd = n - 1;\n                    direc[bigInd] = direc[lastInd];\n                    direc[lastInd] = result[1];\n                }\n            }\n        }\n    }\n\n    \n    private double[][] newPointAndDirection(double[] p, double[] d, double optimum) {\n        final int n = p.length;\n        final double[] nP = new double[n];\n        final double[] nD = new double[n];\n        for (int i = 0; i < n; i++) {\n            nD[i] = d[i] * optimum;\n            nP[i] = p[i] + nD[i];\n        }\n\n        final double[][] result = new double[2][];\n        result[0] = nP;\n        result[1] = nD;\n\n        return result;\n    }\n\n    \n    private class LineSearch extends BrentOptimizer { private static final double REL_TOL_UNUSED = 1e-15; private static final double ABS_TOL_UNUSED = Double.MIN_VALUE; private final BracketFinder bracket = new BracketFinder(); LineSearch(double rel, double abs) {\n            super(REL_TOL_UNUSED,\n                  ABS_TOL_UNUSED,\n                  new SimpleUnivariateValueChecker(rel, abs));\n        }\n\n        \n        public UnivariatePointValuePair search(final double[] p, final double[] d) {\n            final int n = p.length;\n            final UnivariateFunction f = new UnivariateFunction() {\n                    public double value(double alpha) {\n                        final double[] x = new double[n];\n                        for (int i = 0; i < n; i++) {\n                            x[i] = p[i] + alpha * d[i];\n                        }\n                        final double obj = PowellOptimizer.this.computeObjectiveValue(x);\n                        return obj;\n                    }\n                };\n\n            final GoalType goal = PowellOptimizer.this.getGoalType();\n            bracket.search(f, goal, 0, 1);\n            \n            \n            \n            return optimize(new MaxEval(Integer.MAX_VALUE),\n                            new UnivariateObjectiveFunction(f),\n                            goal,\n                            new SearchInterval(bracket.getLo(),\n                                               bracket.getHi(),\n                                               bracket.getMid()));\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "fixed_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n\nimport org.apache.commons.math3.util.FastMath;\nimport org.apache.commons.math3.util.MathArrays;\nimport org.apache.commons.math3.analysis.UnivariateFunction;\nimport org.apache.commons.math3.exception.NumberIsTooSmallException;\nimport org.apache.commons.math3.exception.NotStrictlyPositiveException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.MaxEval;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\nimport org.apache.commons.math3.optim.univariate.BracketFinder;\nimport org.apache.commons.math3.optim.univariate.BrentOptimizer;\nimport org.apache.commons.math3.optim.univariate.UnivariatePointValuePair;\nimport org.apache.commons.math3.optim.univariate.SimpleUnivariateValueChecker;\nimport org.apache.commons.math3.optim.univariate.SearchInterval;\nimport org.apache.commons.math3.optim.univariate.UnivariateObjectiveFunction;\n\n\npublic class PowellOptimizer extends MultivariateOptimizer { private static final double MIN_RELATIVE_TOLERANCE = 2 * FastMath.ulp(1d); private final double relativeThreshold; private final double absoluteThreshold; private final LineSearch line; public PowellOptimizer(double rel, double abs, ConvergenceChecker<PointValuePair> checker) {\n        this(rel, abs, FastMath.sqrt(rel), FastMath.sqrt(abs), checker);\n    }\n\n    \n    public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs, ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n\n        if (rel < MIN_RELATIVE_TOLERANCE) {\n            throw new NumberIsTooSmallException(rel, MIN_RELATIVE_TOLERANCE, true);\n        }\n        if (abs <= 0) {\n            throw new NotStrictlyPositiveException(abs);\n        }\n        relativeThreshold = rel;\n        absoluteThreshold = abs;\n\n        \n        line = new LineSearch(lineRel,\n                              lineAbs);\n    }\n\n    \n    public PowellOptimizer(double rel, double abs) {\n        this(rel, abs, null);\n    }\n\n    \n    public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs) {\n        this(rel, abs, lineRel, lineAbs, null);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n        checkParameters();\n\n        final GoalType goal = getGoalType();\n        final double[] guess = getStartPoint();\n        final int n = guess.length;\n\n        final double[][] direc = new double[n][n];\n        for (int i = 0; i < n; i++) {\n            direc[i][i] = 1;\n        }\n\n        final ConvergenceChecker<PointValuePair> checker\n            = getConvergenceChecker();\n\n        double[] x = guess;\n        double fVal = computeObjectiveValue(x);\n        double[] x1 = x.clone();\n        while (true) {\n            incrementIterationCount();\n\n            double fX = fVal;\n            double fX2 = 0;\n            double delta = 0;\n            int bigInd = 0;\n            double alphaMin = 0;\n\n            for (int i = 0; i < n; i++) {\n                final double[] d = MathArrays.copyOf(direc[i]);\n\n                fX2 = fVal;\n\n                final UnivariatePointValuePair optimum = line.search(x, d);\n                fVal = optimum.getValue();\n                alphaMin = optimum.getPoint();\n                final double[][] result = newPointAndDirection(x, d, alphaMin);\n                x = result[0];\n\n                if ((fX2 - fVal) > delta) {\n                    delta = fX2 - fVal;\n                    bigInd = i;\n                }\n            }\n\n            \n            boolean stop = 2 * (fX - fVal) <=\n                (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) +\n                 absoluteThreshold);\n\n            final PointValuePair previous = new PointValuePair(x1, fX);\n            final PointValuePair current = new PointValuePair(x, fVal);\n            if (!stop) { \n                if (checker != null) {\n                    stop = checker.converged(getIterations(), previous, current);\n                }\n            }\n            if (stop) {\n                if (goal == GoalType.MINIMIZE) {\n                    return (fVal < fX) ? current : previous;\n                } else {\n                    return (fVal > fX) ? current : previous;\n                }\n            }\n\n            final double[] d = new double[n];\n            final double[] x2 = new double[n];\n            for (int i = 0; i < n; i++) {\n                d[i] = x[i] - x1[i];\n                x2[i] = 2 * x[i] - x1[i];\n            }\n\n            x1 = x.clone();\n            fX2 = computeObjectiveValue(x2);\n\n            if (fX > fX2) {\n                double t = 2 * (fX + fX2 - 2 * fVal);\n                double temp = fX - fVal - delta;\n                t *= temp * temp;\n                temp = fX - fX2;\n                t -= delta * temp * temp;\n\n                if (t < 0.0) {\n                    final UnivariatePointValuePair optimum = line.search(x, d);\n                    fVal = optimum.getValue();\n                    alphaMin = optimum.getPoint();\n                    final double[][] result = newPointAndDirection(x, d, alphaMin);\n                    x = result[0];\n\n                    final int lastInd = n - 1;\n                    direc[bigInd] = direc[lastInd];\n                    direc[lastInd] = result[1];\n                }\n            }\n        }\n    }\n\n    \n    private double[][] newPointAndDirection(double[] p, double[] d, double optimum) {\n        final int n = p.length;\n        final double[] nP = new double[n];\n        final double[] nD = new double[n];\n        for (int i = 0; i < n; i++) {\n            nD[i] = d[i] * optimum;\n            nP[i] = p[i] + nD[i];\n        }\n\n        final double[][] result = new double[2][];\n        result[0] = nP;\n        result[1] = nD;\n\n        return result;\n    }\n\n    \n    private class LineSearch extends BrentOptimizer { private static final double REL_TOL_UNUSED = 1e-15; private static final double ABS_TOL_UNUSED = Double.MIN_VALUE; private final BracketFinder bracket = new BracketFinder(); LineSearch(double rel, double abs) {\n            super(REL_TOL_UNUSED,\n                  ABS_TOL_UNUSED,\n                  new SimpleUnivariateValueChecker(rel, abs));\n        }\n\n        \n        public UnivariatePointValuePair search(final double[] p, final double[] d) {\n            final int n = p.length;\n            final UnivariateFunction f = new UnivariateFunction() {\n                    public double value(double alpha) {\n                        final double[] x = new double[n];\n                        for (int i = 0; i < n; i++) {\n                            x[i] = p[i] + alpha * d[i];\n                        }\n                        final double obj = PowellOptimizer.this.computeObjectiveValue(x);\n                        return obj;\n                    }\n                };\n\n            final GoalType goal = PowellOptimizer.this.getGoalType();\n            bracket.search(f, goal, 0, 1);\n            \n            \n            \n            return optimize(new MaxEval(Integer.MAX_VALUE),\n                            new UnivariateObjectiveFunction(f),\n                            goal,\n                            new SearchInterval(bracket.getLo(),\n                                               bracket.getHi(),\n                                               bracket.getMid()));\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "buggy_signatures": [
        "public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs, ConvergenceChecker<PointValuePair> checker)",
        "public PowellOptimizer(double rel, double abs)",
        "public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs)",
        "protected PointValuePair doOptimize()",
        "private double[][] newPointAndDirection(double[] p, double[] d, double optimum)",
        "public UnivariatePointValuePair search(final double[] p, final double[] d)",
        "public double value(double alpha)",
        "private void checkParameters()"
      ],
      "fixed_signatures": [
        "public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs, ConvergenceChecker<PointValuePair> checker)",
        "public PowellOptimizer(double rel, double abs)",
        "public PowellOptimizer(double rel, double abs, double lineRel, double lineAbs)",
        "protected PointValuePair doOptimize()",
        "private double[][] newPointAndDirection(double[] p, double[] d, double optimum)",
        "public UnivariatePointValuePair search(final double[] p, final double[] d)",
        "public double value(double alpha)",
        "private void checkParameters()"
      ],
      "methods": [
        {
          "buggy_method": "  protected PointValuePair doOptimize() {\n  checkParameters();\n\n  final GoalType goal = getGoalType();\n  final double[] guess = getStartPoint();\n  final int n = guess.length;\n\n  final double[][] direc = new double[n][n];\n  for (int i = 0; i < n; i++) {\n  direc[i][i] = 1;\n  }\n\n  final ConvergenceChecker<PointValuePair> checker\n  = getConvergenceChecker();\n\n  double[] x = guess;\n  double fVal = computeObjectiveValue(x);\n  double[] x1 = x.clone();\n  int iter = 0;\n  while (true) {\n  ++iter;\n\n  double fX = fVal;\n  double fX2 = 0;\n  double delta = 0;\n  int bigInd = 0;\n  double alphaMin = 0;\n\n  for (int i = 0; i < n; i++) {\n  final double[] d = MathArrays.copyOf(direc[i]);\n\n  fX2 = fVal;\n\n  final UnivariatePointValuePair optimum = line.search(x, d);\n  fVal = optimum.getValue();\n  alphaMin = optimum.getPoint();\n  final double[][] result = newPointAndDirection(x, d, alphaMin);\n  x = result[0];\n\n  if ((fX2 - fVal) > delta) {\n  delta = fX2 - fVal;\n  bigInd = i;\n  }\n  }\n\n  \n  boolean stop = 2 * (fX - fVal) <=\n  (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) +\n  absoluteThreshold);\n\n  final PointValuePair previous = new PointValuePair(x1, fX);\n  final PointValuePair current = new PointValuePair(x, fVal);\n  if (!stop) { \n  if (checker != null) {\n  stop = checker.converged(iter, previous, current);\n  }\n  }\n  if (stop) {\n  if (goal == GoalType.MINIMIZE) {\n  return (fVal < fX) ? current : previous;\n  } else {\n  return (fVal > fX) ? current : previous;\n  }\n  }\n\n  final double[] d = new double[n];\n  final double[] x2 = new double[n];\n  for (int i = 0; i < n; i++) {\n  d[i] = x[i] - x1[i];\n  x2[i] = 2 * x[i] - x1[i];\n  }\n\n  x1 = x.clone();\n  fX2 = computeObjectiveValue(x2);\n\n  if (fX > fX2) {\n  double t = 2 * (fX + fX2 - 2 * fVal);\n  double temp = fX - fVal - delta;\n  t *= temp * temp;\n  temp = fX - fX2;\n  t -= delta * temp * temp;\n\n  if (t < 0.0) {\n  final UnivariatePointValuePair optimum = line.search(x, d);\n  fVal = optimum.getValue();\n  alphaMin = optimum.getPoint();\n  final double[][] result = newPointAndDirection(x, d, alphaMin);\n  x = result[0];\n\n  final int lastInd = n - 1;\n  direc[bigInd] = direc[lastInd];\n  direc[lastInd] = result[1];\n  }\n  }\n  }\n  }",
          "fixed_method": "  protected PointValuePair doOptimize() {\n  checkParameters();\n\n  final GoalType goal = getGoalType();\n  final double[] guess = getStartPoint();\n  final int n = guess.length;\n\n  final double[][] direc = new double[n][n];\n  for (int i = 0; i < n; i++) {\n  direc[i][i] = 1;\n  }\n\n  final ConvergenceChecker<PointValuePair> checker\n  = getConvergenceChecker();\n\n  double[] x = guess;\n  double fVal = computeObjectiveValue(x);\n  double[] x1 = x.clone();\n  while (true) {\n  incrementIterationCount();\n\n  double fX = fVal;\n  double fX2 = 0;\n  double delta = 0;\n  int bigInd = 0;\n  double alphaMin = 0;\n\n  for (int i = 0; i < n; i++) {\n  final double[] d = MathArrays.copyOf(direc[i]);\n\n  fX2 = fVal;\n\n  final UnivariatePointValuePair optimum = line.search(x, d);\n  fVal = optimum.getValue();\n  alphaMin = optimum.getPoint();\n  final double[][] result = newPointAndDirection(x, d, alphaMin);\n  x = result[0];\n\n  if ((fX2 - fVal) > delta) {\n  delta = fX2 - fVal;\n  bigInd = i;\n  }\n  }\n\n  \n  boolean stop = 2 * (fX - fVal) <=\n  (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) +\n  absoluteThreshold);\n\n  final PointValuePair previous = new PointValuePair(x1, fX);\n  final PointValuePair current = new PointValuePair(x, fVal);\n  if (!stop) { \n  if (checker != null) {\n  stop = checker.converged(getIterations(), previous, current);\n  }\n  }\n  if (stop) {\n  if (goal == GoalType.MINIMIZE) {\n  return (fVal < fX) ? current : previous;\n  } else {\n  return (fVal > fX) ? current : previous;\n  }\n  }\n\n  final double[] d = new double[n];\n  final double[] x2 = new double[n];\n  for (int i = 0; i < n; i++) {\n  d[i] = x[i] - x1[i];\n  x2[i] = 2 * x[i] - x1[i];\n  }\n\n  x1 = x.clone();\n  fX2 = computeObjectiveValue(x2);\n\n  if (fX > fX2) {\n  double t = 2 * (fX + fX2 - 2 * fVal);\n  double temp = fX - fVal - delta;\n  t *= temp * temp;\n  temp = fX - fX2;\n  t -= delta * temp * temp;\n\n  if (t < 0.0) {\n  final UnivariatePointValuePair optimum = line.search(x, d);\n  fVal = optimum.getValue();\n  alphaMin = optimum.getPoint();\n  final double[][] result = newPointAndDirection(x, d, alphaMin);\n  x = result[0];\n\n  final int lastInd = n - 1;\n  direc[bigInd] = direc[lastInd];\n  direc[lastInd] = result[1];\n  }\n  }\n  }\n  }",
          "diff": [
            "@@ -188,9 +188,8 @@",
            "         double[] x = guess;\n",
            "         double fVal = computeObjectiveValue(x);\n",
            "         double[] x1 = x.clone();\n",
            "-        int iter = 0;\n",
            "         while (true) {\n",
            "-            ++iter;\n",
            "+            incrementIterationCount();\n",
            " \n",
            "             double fX = fVal;\n",
            "             double fX2 = 0;\n",
            "@@ -224,7 +223,7 @@",
            "             final PointValuePair current = new PointValuePair(x, fVal);\n",
            "             if (!stop) { // User-defined stopping criteria.\n",
            "                 if (checker != null) {\n",
            "-                    stop = checker.converged(iter, previous, current);\n",
            "+                    stop = checker.converged(getIterations(), previous, current);\n",
            "                 }\n",
            "             }\n",
            "             if (stop) {\n"
          ],
          "changed_lines": 5
        }
      ]
    },
    {
      "name": "org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java",
      "buggy_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n\nimport java.util.Comparator;\nimport org.apache.commons.math3.analysis.MultivariateFunction;\nimport org.apache.commons.math3.exception.NullArgumentException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.SimpleValueChecker;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n\n\npublic class SimplexOptimizer extends MultivariateOptimizer { private AbstractSimplex simplex; public SimplexOptimizer(ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n    }\n\n    \n    public SimplexOptimizer(double rel, double abs) {\n        this(new SimpleValueChecker(rel, abs));\n    }\n\n    \n    @Override\n    public PointValuePair optimize(OptimizationData... optData) {\n        \n        return super.optimize(optData);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n        checkParameters();\n\n        \n        \n        final MultivariateFunction evalFunc\n            = new MultivariateFunction() {\n                public double value(double[] point) {\n                    return computeObjectiveValue(point);\n                }\n            };\n\n        final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n        final Comparator<PointValuePair> comparator\n            = new Comparator<PointValuePair>() {\n            public int compare(final PointValuePair o1, final PointValuePair o2) {\n                final double v1 = o1.getValue();\n                final double v2 = o2.getValue();\n                return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n            }\n        };\n\n        \n        simplex.build(getStartPoint());\n        simplex.evaluate(evalFunc, comparator);\n\n        PointValuePair[] previous = null;\n        int iteration = 0;\n        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n        while (true) {\n            if (iteration > 0) {\n                boolean converged = true;\n                for (int i = 0; i < simplex.getSize(); i++) {\n                    PointValuePair prev = previous[i];\n                    converged = converged &&\n                        checker.converged(iteration, prev, simplex.getPoint(i));\n                }\n                if (converged) {\n                    \n                    return simplex.getPoint(0);\n                }\n            }\n\n            \n            previous = simplex.getPoints();\n            simplex.iterate(evalFunc, comparator);\n\n\t\t\t++iteration;\n        }\n    }\n\n    \n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        super.parseOptimizationData(optData);\n\n        \n        \n        for (OptimizationData data : optData) {\n            if (data instanceof AbstractSimplex) {\n                simplex = (AbstractSimplex) data;\n                \n                \n                break;\n            }\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (simplex == null) {\n            throw new NullArgumentException();\n        }\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "fixed_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n\nimport java.util.Comparator;\nimport org.apache.commons.math3.analysis.MultivariateFunction;\nimport org.apache.commons.math3.exception.NullArgumentException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.SimpleValueChecker;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n\n\npublic class SimplexOptimizer extends MultivariateOptimizer { private AbstractSimplex simplex; public SimplexOptimizer(ConvergenceChecker<PointValuePair> checker) {\n        super(checker);\n    }\n\n    \n    public SimplexOptimizer(double rel, double abs) {\n        this(new SimpleValueChecker(rel, abs));\n    }\n\n    \n    @Override\n    public PointValuePair optimize(OptimizationData... optData) {\n        \n        return super.optimize(optData);\n    }\n\n    \n    @Override\n    protected PointValuePair doOptimize() {\n        checkParameters();\n\n        \n        \n        final MultivariateFunction evalFunc\n            = new MultivariateFunction() {\n                public double value(double[] point) {\n                    return computeObjectiveValue(point);\n                }\n            };\n\n        final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n        final Comparator<PointValuePair> comparator\n            = new Comparator<PointValuePair>() {\n            public int compare(final PointValuePair o1, final PointValuePair o2) {\n                final double v1 = o1.getValue();\n                final double v2 = o2.getValue();\n                return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n            }\n        };\n\n        \n        simplex.build(getStartPoint());\n        simplex.evaluate(evalFunc, comparator);\n\n        PointValuePair[] previous = null;\n        int iteration = 0;\n        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n        while (true) {\n            if (getIterations() > 0) {\n                boolean converged = true;\n                for (int i = 0; i < simplex.getSize(); i++) {\n                    PointValuePair prev = previous[i];\n                    converged = converged &&\n                        checker.converged(iteration, prev, simplex.getPoint(i));\n                }\n                if (converged) {\n                    \n                    return simplex.getPoint(0);\n                }\n            }\n\n            \n            previous = simplex.getPoints();\n            simplex.iterate(evalFunc, comparator);\n\n            incrementIterationCount();\n        }\n    }\n\n    \n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        \n        super.parseOptimizationData(optData);\n\n        \n        \n        for (OptimizationData data : optData) {\n            if (data instanceof AbstractSimplex) {\n                simplex = (AbstractSimplex) data;\n                \n                \n                break;\n            }\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (simplex == null) {\n            throw new NullArgumentException();\n        }\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "buggy_signatures": [
        "public class SimplexOptimizer extends MultivariateOptimizer { private AbstractSimplex simplex; public SimplexOptimizer(ConvergenceChecker<PointValuePair> checker)",
        "public SimplexOptimizer(double rel, double abs)",
        "public PointValuePair optimize(OptimizationData... optData)",
        "protected PointValuePair doOptimize()",
        "public double value(double[] point)",
        "public int compare(final PointValuePair o1, final PointValuePair o2)",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private void checkParameters()"
      ],
      "fixed_signatures": [
        "public class SimplexOptimizer extends MultivariateOptimizer { private AbstractSimplex simplex; public SimplexOptimizer(ConvergenceChecker<PointValuePair> checker)",
        "public SimplexOptimizer(double rel, double abs)",
        "public PointValuePair optimize(OptimizationData... optData)",
        "protected PointValuePair doOptimize()",
        "public double value(double[] point)",
        "public int compare(final PointValuePair o1, final PointValuePair o2)",
        "protected void parseOptimizationData(OptimizationData... optData)",
        "private void checkParameters()"
      ],
      "methods": [
        {
          "buggy_method": "  public int compare(final PointValuePair o1, final PointValuePair o2) {\n  final double v1 = o1.getValue();\n  final double v2 = o2.getValue();\n  return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n  }",
          "fixed_method": "  public int compare(final PointValuePair o1, final PointValuePair o2) {\n  final double v1 = o1.getValue();\n  final double v2 = o2.getValue();\n  return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n  }",
          "diff": [
            "@@ -155,7 +155,7 @@",
            "         int iteration = 0;\n",
            "         final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n",
            "         while (true) {\n",
            "-            if (iteration > 0) {\n",
            "+            if (getIterations() > 0) {\n",
            "                 boolean converged = true;\n",
            "                 for (int i = 0; i < simplex.getSize(); i++) {\n",
            "                     PointValuePair prev = previous[i];\n",
            "@@ -172,7 +172,7 @@",
            "             previous = simplex.getPoints();\n",
            "             simplex.iterate(evalFunc, comparator);\n",
            " \n",
            "-\t\t\t++iteration;\n",
            "+            incrementIterationCount();\n",
            "         }\n",
            "     }\n",
            " \n"
          ],
          "changed_lines": 4
        }
      ]
    },
    {
      "name": "org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java",
      "buggy_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n\nimport org.apache.commons.math3.exception.ConvergenceException;\nimport org.apache.commons.math3.exception.NullArgumentException;\nimport org.apache.commons.math3.exception.MathInternalError;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.linear.ArrayRealVector;\nimport org.apache.commons.math3.linear.BlockRealMatrix;\nimport org.apache.commons.math3.linear.DecompositionSolver;\nimport org.apache.commons.math3.linear.LUDecomposition;\nimport org.apache.commons.math3.linear.QRDecomposition;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.linear.SingularMatrixException;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.PointVectorValuePair;\n\n\npublic class GaussNewtonOptimizer extends AbstractLeastSquaresOptimizer { private final boolean useLU; public GaussNewtonOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n        this(true, checker);\n    }\n\n    \n    public GaussNewtonOptimizer(final boolean useLU, ConvergenceChecker<PointVectorValuePair> checker) {\n        super(checker);\n        this.useLU = useLU;\n    }\n\n    \n    @Override\n    public PointVectorValuePair doOptimize() {\n        checkParameters();\n\n        final ConvergenceChecker<PointVectorValuePair> checker\n            = getConvergenceChecker();\n\n        \n        if (checker == null) {\n            throw new NullArgumentException();\n        }\n\n        final double[] targetValues = getTarget();\n        final int nR = targetValues.length; \n\n        final RealMatrix weightMatrix = getWeight();\n        \n        final double[] residualsWeights = new double[nR];\n        for (int i = 0; i < nR; i++) {\n            residualsWeights[i] = weightMatrix.getEntry(i, i);\n        }\n\n        final double[] currentPoint = getStartPoint();\n        final int nC = currentPoint.length;\n\n        \n        PointVectorValuePair current = null;\n        int iter = 0;\n        for (boolean converged = false; !converged;) {\n            ++iter;\n\n            \n            PointVectorValuePair previous = current;\n            \n            final double[] currentObjective = computeObjectiveValue(currentPoint);\n            final double[] currentResiduals = computeResiduals(currentObjective);\n            final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n            current = new PointVectorValuePair(currentPoint, currentObjective);\n\n            \n            final double[]   b = new double[nC];\n            final double[][] a = new double[nC][nC];\n            for (int i = 0; i < nR; ++i) {\n\n                final double[] grad   = weightedJacobian.getRow(i);\n                final double weight   = residualsWeights[i];\n                final double residual = currentResiduals[i];\n\n                \n                final double wr = weight * residual;\n                for (int j = 0; j < nC; ++j) {\n                    b[j] += wr * grad[j];\n                }\n\n                \n                for (int k = 0; k < nC; ++k) {\n                    double[] ak = a[k];\n                    double wgk = weight * grad[k];\n                    for (int l = 0; l < nC; ++l) {\n                        ak[l] += wgk * grad[l];\n                    }\n                }\n            }\n\n            try {\n                \n                RealMatrix mA = new BlockRealMatrix(a);\n                DecompositionSolver solver = useLU ?\n                        new LUDecomposition(mA).getSolver() :\n                        new QRDecomposition(mA).getSolver();\n                final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n                \n                for (int i = 0; i < nC; ++i) {\n                    currentPoint[i] += dX[i];\n                }\n            } catch (SingularMatrixException e) {\n                throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n            }\n\n            \n            if (previous != null) {\n                converged = checker.converged(iter, previous, current);\n                if (converged) {\n                    setCost(computeCost(currentResiduals));\n                    return current;\n                }\n            }\n        }\n        \n        throw new MathInternalError();\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "fixed_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n\nimport org.apache.commons.math3.exception.ConvergenceException;\nimport org.apache.commons.math3.exception.NullArgumentException;\nimport org.apache.commons.math3.exception.MathInternalError;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.linear.ArrayRealVector;\nimport org.apache.commons.math3.linear.BlockRealMatrix;\nimport org.apache.commons.math3.linear.DecompositionSolver;\nimport org.apache.commons.math3.linear.LUDecomposition;\nimport org.apache.commons.math3.linear.QRDecomposition;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.linear.SingularMatrixException;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.PointVectorValuePair;\n\n\npublic class GaussNewtonOptimizer extends AbstractLeastSquaresOptimizer { private final boolean useLU; public GaussNewtonOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n        this(true, checker);\n    }\n\n    \n    public GaussNewtonOptimizer(final boolean useLU, ConvergenceChecker<PointVectorValuePair> checker) {\n        super(checker);\n        this.useLU = useLU;\n    }\n\n    \n    @Override\n    public PointVectorValuePair doOptimize() {\n        checkParameters();\n\n        final ConvergenceChecker<PointVectorValuePair> checker\n            = getConvergenceChecker();\n\n        \n        if (checker == null) {\n            throw new NullArgumentException();\n        }\n\n        final double[] targetValues = getTarget();\n        final int nR = targetValues.length; \n\n        final RealMatrix weightMatrix = getWeight();\n        \n        final double[] residualsWeights = new double[nR];\n        for (int i = 0; i < nR; i++) {\n            residualsWeights[i] = weightMatrix.getEntry(i, i);\n        }\n\n        final double[] currentPoint = getStartPoint();\n        final int nC = currentPoint.length;\n\n        \n        PointVectorValuePair current = null;\n        for (boolean converged = false; !converged;) {\n            incrementIterationCount();\n\n            \n            PointVectorValuePair previous = current;\n            \n            final double[] currentObjective = computeObjectiveValue(currentPoint);\n            final double[] currentResiduals = computeResiduals(currentObjective);\n            final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n            current = new PointVectorValuePair(currentPoint, currentObjective);\n\n            \n            final double[]   b = new double[nC];\n            final double[][] a = new double[nC][nC];\n            for (int i = 0; i < nR; ++i) {\n\n                final double[] grad   = weightedJacobian.getRow(i);\n                final double weight   = residualsWeights[i];\n                final double residual = currentResiduals[i];\n\n                \n                final double wr = weight * residual;\n                for (int j = 0; j < nC; ++j) {\n                    b[j] += wr * grad[j];\n                }\n\n                \n                for (int k = 0; k < nC; ++k) {\n                    double[] ak = a[k];\n                    double wgk = weight * grad[k];\n                    for (int l = 0; l < nC; ++l) {\n                        ak[l] += wgk * grad[l];\n                    }\n                }\n            }\n\n            try {\n                \n                RealMatrix mA = new BlockRealMatrix(a);\n                DecompositionSolver solver = useLU ?\n                        new LUDecomposition(mA).getSolver() :\n                        new QRDecomposition(mA).getSolver();\n                final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n                \n                for (int i = 0; i < nC; ++i) {\n                    currentPoint[i] += dX[i];\n                }\n            } catch (SingularMatrixException e) {\n                throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n            }\n\n            \n            if (previous != null) {\n                converged = checker.converged(getIterations(), previous, current);\n                if (converged) {\n                    setCost(computeCost(currentResiduals));\n                    return current;\n                }\n            }\n        }\n        \n        throw new MathInternalError();\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "buggy_signatures": [
        "public class GaussNewtonOptimizer extends AbstractLeastSquaresOptimizer { private final boolean useLU; public GaussNewtonOptimizer(ConvergenceChecker<PointVectorValuePair> checker)",
        "public GaussNewtonOptimizer(final boolean useLU, ConvergenceChecker<PointVectorValuePair> checker)",
        "public PointVectorValuePair doOptimize()",
        "private void checkParameters()"
      ],
      "fixed_signatures": [
        "public class GaussNewtonOptimizer extends AbstractLeastSquaresOptimizer { private final boolean useLU; public GaussNewtonOptimizer(ConvergenceChecker<PointVectorValuePair> checker)",
        "public GaussNewtonOptimizer(final boolean useLU, ConvergenceChecker<PointVectorValuePair> checker)",
        "public PointVectorValuePair doOptimize()",
        "private void checkParameters()"
      ],
      "methods": [
        {
          "buggy_method": "  public PointVectorValuePair doOptimize() {\n  checkParameters();\n\n  final ConvergenceChecker<PointVectorValuePair> checker\n  = getConvergenceChecker();\n\n  \n  if (checker == null) {\n  throw new NullArgumentException();\n  }\n\n  final double[] targetValues = getTarget();\n  final int nR = targetValues.length; \n\n  final RealMatrix weightMatrix = getWeight();\n  \n  final double[] residualsWeights = new double[nR];\n  for (int i = 0; i < nR; i++) {\n  residualsWeights[i] = weightMatrix.getEntry(i, i);\n  }\n\n  final double[] currentPoint = getStartPoint();\n  final int nC = currentPoint.length;\n\n  \n  PointVectorValuePair current = null;\n  int iter = 0;\n  for (boolean converged = false; !converged;) {\n  ++iter;\n\n  \n  PointVectorValuePair previous = current;\n  \n  final double[] currentObjective = computeObjectiveValue(currentPoint);\n  final double[] currentResiduals = computeResiduals(currentObjective);\n  final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n  current = new PointVectorValuePair(currentPoint, currentObjective);\n\n  \n  final double[]  b = new double[nC];\n  final double[][] a = new double[nC][nC];\n  for (int i = 0; i < nR; ++i) {\n\n  final double[] grad  = weightedJacobian.getRow(i);\n  final double weight  = residualsWeights[i];\n  final double residual = currentResiduals[i];\n\n  \n  final double wr = weight * residual;\n  for (int j = 0; j < nC; ++j) {\n  b[j] += wr * grad[j];\n  }\n\n  \n  for (int k = 0; k < nC; ++k) {\n  double[] ak = a[k];\n  double wgk = weight * grad[k];\n  for (int l = 0; l < nC; ++l) {\n  ak[l] += wgk * grad[l];\n  }\n  }\n  }\n\n  try {\n  \n  RealMatrix mA = new BlockRealMatrix(a);\n  DecompositionSolver solver = useLU ?\n  new LUDecomposition(mA).getSolver() :\n  new QRDecomposition(mA).getSolver();\n  final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n  \n  for (int i = 0; i < nC; ++i) {\n  currentPoint[i] += dX[i];\n  }\n  } catch (SingularMatrixException e) {\n  throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n  }\n\n  \n  if (previous != null) {\n  converged = checker.converged(iter, previous, current);\n  if (converged) {\n  setCost(computeCost(currentResiduals));\n  return current;\n  }\n  }\n  }\n  \n  throw new MathInternalError();\n  }",
          "fixed_method": "  public PointVectorValuePair doOptimize() {\n  checkParameters();\n\n  final ConvergenceChecker<PointVectorValuePair> checker\n  = getConvergenceChecker();\n\n  \n  if (checker == null) {\n  throw new NullArgumentException();\n  }\n\n  final double[] targetValues = getTarget();\n  final int nR = targetValues.length; \n\n  final RealMatrix weightMatrix = getWeight();\n  \n  final double[] residualsWeights = new double[nR];\n  for (int i = 0; i < nR; i++) {\n  residualsWeights[i] = weightMatrix.getEntry(i, i);\n  }\n\n  final double[] currentPoint = getStartPoint();\n  final int nC = currentPoint.length;\n\n  \n  PointVectorValuePair current = null;\n  for (boolean converged = false; !converged;) {\n  incrementIterationCount();\n\n  \n  PointVectorValuePair previous = current;\n  \n  final double[] currentObjective = computeObjectiveValue(currentPoint);\n  final double[] currentResiduals = computeResiduals(currentObjective);\n  final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n  current = new PointVectorValuePair(currentPoint, currentObjective);\n\n  \n  final double[]  b = new double[nC];\n  final double[][] a = new double[nC][nC];\n  for (int i = 0; i < nR; ++i) {\n\n  final double[] grad  = weightedJacobian.getRow(i);\n  final double weight  = residualsWeights[i];\n  final double residual = currentResiduals[i];\n\n  \n  final double wr = weight * residual;\n  for (int j = 0; j < nC; ++j) {\n  b[j] += wr * grad[j];\n  }\n\n  \n  for (int k = 0; k < nC; ++k) {\n  double[] ak = a[k];\n  double wgk = weight * grad[k];\n  for (int l = 0; l < nC; ++l) {\n  ak[l] += wgk * grad[l];\n  }\n  }\n  }\n\n  try {\n  \n  RealMatrix mA = new BlockRealMatrix(a);\n  DecompositionSolver solver = useLU ?\n  new LUDecomposition(mA).getSolver() :\n  new QRDecomposition(mA).getSolver();\n  final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n  \n  for (int i = 0; i < nC; ++i) {\n  currentPoint[i] += dX[i];\n  }\n  } catch (SingularMatrixException e) {\n  throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n  }\n\n  \n  if (previous != null) {\n  converged = checker.converged(getIterations(), previous, current);\n  if (converged) {\n  setCost(computeCost(currentResiduals));\n  return current;\n  }\n  }\n  }\n  \n  throw new MathInternalError();\n  }",
          "diff": [
            "@@ -103,9 +103,8 @@",
            " \n",
            "         // iterate until convergence is reached\n",
            "         PointVectorValuePair current = null;\n",
            "-        int iter = 0;\n",
            "         for (boolean converged = false; !converged;) {\n",
            "-            ++iter;\n",
            "+            incrementIterationCount();\n",
            " \n",
            "             // evaluate the objective function and its jacobian\n",
            "             PointVectorValuePair previous = current;\n",
            "@@ -157,7 +156,7 @@",
            " \n",
            "             // Check convergence.\n",
            "             if (previous != null) {\n",
            "-                converged = checker.converged(iter, previous, current);\n",
            "+                converged = checker.converged(getIterations(), previous, current);\n",
            "                 if (converged) {\n",
            "                     setCost(computeCost(currentResiduals));\n",
            "                     return current;\n"
          ],
          "changed_lines": 5
        }
      ]
    },
    {
      "name": "org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java",
      "buggy_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n\nimport java.util.Arrays;\nimport org.apache.commons.math3.exception.ConvergenceException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.PointVectorValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.util.Precision;\nimport org.apache.commons.math3.util.FastMath;\n\n\n\npublic class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer { private int solvedCols; private double[] diagR; private double[] jacNorm; private double[] beta; private int[] permutation; private int rank; private double lmPar; private double[] lmDir; private final double initialStepBoundFactor; private final double costRelativeTolerance; private final double parRelativeTolerance; private final double orthoTolerance; private final double qrRankingThreshold; private double[] weightedResidual; private double[][] weightedJacobian; public LevenbergMarquardtOptimizer() {\n        this(100, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);\n    }\n\n    \n    public LevenbergMarquardtOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n        this(100, checker, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);\n    }\n\n    \n    public LevenbergMarquardtOptimizer(double initialStepBoundFactor, ConvergenceChecker<PointVectorValuePair> checker, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold) {\n        super(checker);\n        this.initialStepBoundFactor = initialStepBoundFactor;\n        this.costRelativeTolerance = costRelativeTolerance;\n        this.parRelativeTolerance = parRelativeTolerance;\n        this.orthoTolerance = orthoTolerance;\n        this.qrRankingThreshold = threshold;\n    }\n\n    \n    public LevenbergMarquardtOptimizer(double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance) {\n        this(100,\n             costRelativeTolerance, parRelativeTolerance, orthoTolerance,\n             Precision.SAFE_MIN);\n    }\n\n    \n    public LevenbergMarquardtOptimizer(double initialStepBoundFactor, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold) {\n        super(null); \n        this.initialStepBoundFactor = initialStepBoundFactor;\n        this.costRelativeTolerance = costRelativeTolerance;\n        this.parRelativeTolerance = parRelativeTolerance;\n        this.orthoTolerance = orthoTolerance;\n        this.qrRankingThreshold = threshold;\n    }\n\n    \n    @Override\n    protected PointVectorValuePair doOptimize() {\n        checkParameters();\n\n        final int nR = getTarget().length; \n        final double[] currentPoint = getStartPoint();\n        final int nC = currentPoint.length; \n\n        \n        solvedCols  = FastMath.min(nR, nC);\n        diagR       = new double[nC];\n        jacNorm     = new double[nC];\n        beta        = new double[nC];\n        permutation = new int[nC];\n        lmDir       = new double[nC];\n\n        \n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[nC];\n        double[] oldX    = new double[nC];\n        double[] oldRes  = new double[nR];\n        double[] oldObj  = new double[nR];\n        double[] qtf     = new double[nR];\n        double[] work1   = new double[nC];\n        double[] work2   = new double[nC];\n        double[] work3   = new double[nC];\n\n        final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n\n        \n        double[] currentObjective = computeObjectiveValue(currentPoint);\n        double[] currentResiduals = computeResiduals(currentObjective);\n        PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n        double currentCost = computeCost(currentResiduals);\n\n        \n        lmPar = 0;\n        boolean firstIteration = true;\n        int iter = 0;\n        final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n        while (true) {\n            ++iter;\n            final PointVectorValuePair previous = current;\n\n            \n            qrDecomposition(computeWeightedJacobian(currentPoint));\n\n            weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n            for (int i = 0; i < nR; i++) {\n                qtf[i] = weightedResidual[i];\n            }\n\n            \n            qTy(qtf);\n\n            \n            \n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                weightedJacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n                \n                \n                xNorm = 0;\n                for (int k = 0; k < nC; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * currentPoint[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = FastMath.sqrt(xNorm);\n\n                \n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n            }\n\n            \n            double maxCosine = 0;\n            if (currentCost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += weightedJacobian[i][pj] * qtf[i];\n                        }\n                        maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                \n                setCost(currentCost);\n                return current;\n            }\n\n            \n            for (int j = 0; j < nC; ++j) {\n                diag[j] = FastMath.max(diag[j], jacNorm[j]);\n            }\n\n            \n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                \n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = currentPoint[pj];\n                }\n                final double previousCost = currentCost;\n                double[] tmpVec = weightedResidual;\n                weightedResidual = oldRes;\n                oldRes    = tmpVec;\n                tmpVec    = currentObjective;\n                currentObjective = oldObj;\n                oldObj    = tmpVec;\n\n                \n                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n\n                \n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    currentPoint[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = FastMath.sqrt(lmNorm);\n                \n                if (firstIteration) {\n                    delta = FastMath.min(delta, lmNorm);\n                }\n\n                \n                currentObjective = computeObjectiveValue(currentPoint);\n                currentResiduals = computeResiduals(currentObjective);\n                current = new PointVectorValuePair(currentPoint, currentObjective);\n                currentCost = computeCost(currentResiduals);\n\n                \n                double actRed = -1.0;\n                if (0.1 * currentCost < previousCost) {\n                    double r = currentCost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                \n                \n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += weightedJacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                \n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                \n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                \n                if (ratio >= 1.0e-4) {\n                    \n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < nC; ++k) {\n                        double xK = diag[k] * currentPoint[k];\n                        xNorm += xK * xK;\n                    }\n                    xNorm = FastMath.sqrt(xNorm);\n\n                    \n                    if (checker != null) {\n                        \n                        if (checker.converged(iter, previous, current)) {\n                            setCost(currentCost);\n                            return current;\n                        }\n                    }\n                } else {\n                    \n                    currentCost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        currentPoint[pj] = oldX[pj];\n                    }\n                    tmpVec    = weightedResidual;\n                    weightedResidual = oldRes;\n                    oldRes    = tmpVec;\n                    tmpVec    = currentObjective;\n                    currentObjective = oldObj;\n                    oldObj    = tmpVec;\n                    \n                    current = new PointVectorValuePair(currentPoint, currentObjective);\n                }\n\n                \n                if ((FastMath.abs(actRed) <= costRelativeTolerance &&\n                     preRed <= costRelativeTolerance &&\n                     ratio <= 2.0) ||\n                    delta <= parRelativeTolerance * xNorm) {\n                    setCost(currentCost);\n                    return current;\n                }\n\n                \n                \n                if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n                                                   costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n                                                   parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n                                                   orthoTolerance);\n                }\n            }\n        }\n    }\n\n    \n    private void determineLMParameter(double[] qy, double delta, double[] diag, double[] work1, double[] work2, double[] work3) {\n        final int nC = weightedJacobian[0].length;\n\n        \n        \n        for (int j = 0; j < rank; ++j) {\n            lmDir[permutation[j]] = qy[j];\n        }\n        for (int j = rank; j < nC; ++j) {\n            lmDir[permutation[j]] = 0;\n        }\n        for (int k = rank - 1; k >= 0; --k) {\n            int pk = permutation[k];\n            double ypk = lmDir[pk] / diagR[pk];\n            for (int i = 0; i < k; ++i) {\n                lmDir[permutation[i]] -= ypk * weightedJacobian[i][pk];\n            }\n            lmDir[pk] = ypk;\n        }\n\n        \n        \n        double dxNorm = 0;\n        for (int j = 0; j < solvedCols; ++j) {\n            int pj = permutation[j];\n            double s = diag[pj] * lmDir[pj];\n            work1[pj] = s;\n            dxNorm += s * s;\n        }\n        dxNorm = FastMath.sqrt(dxNorm);\n        double fp = dxNorm - delta;\n        if (fp <= 0.1 * delta) {\n            lmPar = 0;\n            return;\n        }\n\n        \n        \n        \n        double sum2;\n        double parl = 0;\n        if (rank == solvedCols) {\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] *= diag[pj] / dxNorm;\n            }\n            sum2 = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                double sum = 0;\n                for (int i = 0; i < j; ++i) {\n                    sum += weightedJacobian[i][pj] * work1[permutation[i]];\n                }\n                double s = (work1[pj] - sum) / diagR[pj];\n                work1[pj] = s;\n                sum2 += s * s;\n            }\n            parl = fp / (delta * sum2);\n        }\n\n        \n        sum2 = 0;\n        for (int j = 0; j < solvedCols; ++j) {\n            int pj = permutation[j];\n            double sum = 0;\n            for (int i = 0; i <= j; ++i) {\n                sum += weightedJacobian[i][pj] * qy[i];\n            }\n            sum /= diag[pj];\n            sum2 += sum * sum;\n        }\n        double gNorm = FastMath.sqrt(sum2);\n        double paru = gNorm / delta;\n        if (paru == 0) {\n            \n            paru = 2.2251e-308 / FastMath.min(delta, 0.1);\n        }\n\n        \n        \n        lmPar = FastMath.min(paru, FastMath.max(lmPar, parl));\n        if (lmPar == 0) {\n            lmPar = gNorm / dxNorm;\n        }\n\n        for (int countdown = 10; countdown >= 0; --countdown) {\n\n            \n            if (lmPar == 0) {\n                lmPar = FastMath.max(2.2251e-308, 0.001 * paru);\n            }\n            double sPar = FastMath.sqrt(lmPar);\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] = sPar * diag[pj];\n            }\n            determineLMDirection(qy, work1, work2, work3);\n\n            dxNorm = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                double s = diag[pj] * lmDir[pj];\n                work3[pj] = s;\n                dxNorm += s * s;\n            }\n            dxNorm = FastMath.sqrt(dxNorm);\n            double previousFP = fp;\n            fp = dxNorm - delta;\n\n            \n            \n            if ((FastMath.abs(fp) <= 0.1 * delta) ||\n                    ((parl == 0) && (fp <= previousFP) && (previousFP < 0))) {\n                return;\n            }\n\n            \n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] = work3[pj] * diag[pj] / dxNorm;\n            }\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] /= work2[j];\n                double tmp = work1[pj];\n                for (int i = j + 1; i < solvedCols; ++i) {\n                    work1[permutation[i]] -= weightedJacobian[i][pj] * tmp;\n                }\n            }\n            sum2 = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                double s = work1[permutation[j]];\n                sum2 += s * s;\n            }\n            double correction = fp / (delta * sum2);\n\n            \n            if (fp > 0) {\n                parl = FastMath.max(parl, lmPar);\n            } else if (fp < 0) {\n                paru = FastMath.min(paru, lmPar);\n            }\n\n            \n            lmPar = FastMath.max(parl, lmPar + correction);\n\n        }\n    }\n\n    \n    private void determineLMDirection(double[] qy, double[] diag, double[] lmDiag, double[] work) {\n\n        \n        \n        for (int j = 0; j < solvedCols; ++j) {\n            int pj = permutation[j];\n            for (int i = j + 1; i < solvedCols; ++i) {\n                weightedJacobian[i][pj] = weightedJacobian[j][permutation[i]];\n            }\n            lmDir[j] = diagR[pj];\n            work[j]  = qy[j];\n        }\n\n        \n        for (int j = 0; j < solvedCols; ++j) {\n\n            \n            \n            int pj = permutation[j];\n            double dpj = diag[pj];\n            if (dpj != 0) {\n                Arrays.fill(lmDiag, j + 1, lmDiag.length, 0);\n            }\n            lmDiag[j] = dpj;\n\n            \n            \n            \n            double qtbpj = 0;\n            for (int k = j; k < solvedCols; ++k) {\n                int pk = permutation[k];\n\n                \n                \n                if (lmDiag[k] != 0) {\n\n                    final double sin;\n                    final double cos;\n                    double rkk = weightedJacobian[k][pk];\n                    if (FastMath.abs(rkk) < FastMath.abs(lmDiag[k])) {\n                        final double cotan = rkk / lmDiag[k];\n                        sin   = 1.0 / FastMath.sqrt(1.0 + cotan * cotan);\n                        cos   = sin * cotan;\n                    } else {\n                        final double tan = lmDiag[k] / rkk;\n                        cos = 1.0 / FastMath.sqrt(1.0 + tan * tan);\n                        sin = cos * tan;\n                    }\n\n                    \n                    \n                    weightedJacobian[k][pk] = cos * rkk + sin * lmDiag[k];\n                    final double temp = cos * work[k] + sin * qtbpj;\n                    qtbpj = -sin * work[k] + cos * qtbpj;\n                    work[k] = temp;\n\n                    \n                    for (int i = k + 1; i < solvedCols; ++i) {\n                        double rik = weightedJacobian[i][pk];\n                        final double temp2 = cos * rik + sin * lmDiag[i];\n                        lmDiag[i] = -sin * rik + cos * lmDiag[i];\n                        weightedJacobian[i][pk] = temp2;\n                    }\n                }\n            }\n\n            \n            \n            lmDiag[j] = weightedJacobian[j][permutation[j]];\n            weightedJacobian[j][permutation[j]] = lmDir[j];\n        }\n\n        \n        \n        int nSing = solvedCols;\n        for (int j = 0; j < solvedCols; ++j) {\n            if ((lmDiag[j] == 0) && (nSing == solvedCols)) {\n                nSing = j;\n            }\n            if (nSing < solvedCols) {\n                work[j] = 0;\n            }\n        }\n        if (nSing > 0) {\n            for (int j = nSing - 1; j >= 0; --j) {\n                int pj = permutation[j];\n                double sum = 0;\n                for (int i = j + 1; i < nSing; ++i) {\n                    sum += weightedJacobian[i][pj] * work[i];\n                }\n                work[j] = (work[j] - sum) / lmDiag[j];\n            }\n        }\n\n        \n        for (int j = 0; j < lmDir.length; ++j) {\n            lmDir[permutation[j]] = work[j];\n        }\n    }\n\n    \n    private void qrDecomposition(RealMatrix jacobian) throws ConvergenceException {\n        \n        \n        weightedJacobian = jacobian.scalarMultiply(-1).getData();\n\n        final int nR = weightedJacobian.length;\n        final int nC = weightedJacobian[0].length;\n\n        \n        for (int k = 0; k < nC; ++k) {\n            permutation[k] = k;\n            double norm2 = 0;\n            for (int i = 0; i < nR; ++i) {\n                double akk = weightedJacobian[i][k];\n                norm2 += akk * akk;\n            }\n            jacNorm[k] = FastMath.sqrt(norm2);\n        }\n\n        \n        for (int k = 0; k < nC; ++k) {\n\n            \n            int nextColumn = -1;\n            double ak2 = Double.NEGATIVE_INFINITY;\n            for (int i = k; i < nC; ++i) {\n                double norm2 = 0;\n                for (int j = k; j < nR; ++j) {\n                    double aki = weightedJacobian[j][permutation[i]];\n                    norm2 += aki * aki;\n                }\n                if (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\n                    throw new ConvergenceException(LocalizedFormats.UNABLE_TO_PERFORM_QR_DECOMPOSITION_ON_JACOBIAN,\n                                                   nR, nC);\n                }\n                if (norm2 > ak2) {\n                    nextColumn = i;\n                    ak2        = norm2;\n                }\n            }\n            if (ak2 <= qrRankingThreshold) {\n                rank = k;\n                return;\n            }\n            int pk                  = permutation[nextColumn];\n            permutation[nextColumn] = permutation[k];\n            permutation[k]          = pk;\n\n            \n            double akk   = weightedJacobian[k][pk];\n            double alpha = (akk > 0) ? -FastMath.sqrt(ak2) : FastMath.sqrt(ak2);\n            double betak = 1.0 / (ak2 - akk * alpha);\n            beta[pk]     = betak;\n\n            \n            diagR[pk]        = alpha;\n            weightedJacobian[k][pk] -= alpha;\n\n            \n            for (int dk = nC - 1 - k; dk > 0; --dk) {\n                double gamma = 0;\n                for (int j = k; j < nR; ++j) {\n                    gamma += weightedJacobian[j][pk] * weightedJacobian[j][permutation[k + dk]];\n                }\n                gamma *= betak;\n                for (int j = k; j < nR; ++j) {\n                    weightedJacobian[j][permutation[k + dk]] -= gamma * weightedJacobian[j][pk];\n                }\n            }\n        }\n        rank = solvedCols;\n    }\n\n    \n    private void qTy(double[] y) {\n        final int nR = weightedJacobian.length;\n        final int nC = weightedJacobian[0].length;\n\n        for (int k = 0; k < nC; ++k) {\n            int pk = permutation[k];\n            double gamma = 0;\n            for (int i = k; i < nR; ++i) {\n                gamma += weightedJacobian[i][pk] * y[i];\n            }\n            gamma *= beta[pk];\n            for (int i = k; i < nR; ++i) {\n                y[i] -= gamma * weightedJacobian[i][pk];\n            }\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "fixed_full_code": "\npackage org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n\nimport java.util.Arrays;\nimport org.apache.commons.math3.exception.ConvergenceException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.PointVectorValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.util.Precision;\nimport org.apache.commons.math3.util.FastMath;\n\n\n\npublic class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer { private int solvedCols; private double[] diagR; private double[] jacNorm; private double[] beta; private int[] permutation; private int rank; private double lmPar; private double[] lmDir; private final double initialStepBoundFactor; private final double costRelativeTolerance; private final double parRelativeTolerance; private final double orthoTolerance; private final double qrRankingThreshold; private double[] weightedResidual; private double[][] weightedJacobian; public LevenbergMarquardtOptimizer() {\n        this(100, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);\n    }\n\n    \n    public LevenbergMarquardtOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n        this(100, checker, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);\n    }\n\n    \n    public LevenbergMarquardtOptimizer(double initialStepBoundFactor, ConvergenceChecker<PointVectorValuePair> checker, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold) {\n        super(checker);\n        this.initialStepBoundFactor = initialStepBoundFactor;\n        this.costRelativeTolerance = costRelativeTolerance;\n        this.parRelativeTolerance = parRelativeTolerance;\n        this.orthoTolerance = orthoTolerance;\n        this.qrRankingThreshold = threshold;\n    }\n\n    \n    public LevenbergMarquardtOptimizer(double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance) {\n        this(100,\n             costRelativeTolerance, parRelativeTolerance, orthoTolerance,\n             Precision.SAFE_MIN);\n    }\n\n    \n    public LevenbergMarquardtOptimizer(double initialStepBoundFactor, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold) {\n        super(null); \n        this.initialStepBoundFactor = initialStepBoundFactor;\n        this.costRelativeTolerance = costRelativeTolerance;\n        this.parRelativeTolerance = parRelativeTolerance;\n        this.orthoTolerance = orthoTolerance;\n        this.qrRankingThreshold = threshold;\n    }\n\n    \n    @Override\n    protected PointVectorValuePair doOptimize() {\n        checkParameters();\n\n        final int nR = getTarget().length; \n        final double[] currentPoint = getStartPoint();\n        final int nC = currentPoint.length; \n\n        \n        solvedCols  = FastMath.min(nR, nC);\n        diagR       = new double[nC];\n        jacNorm     = new double[nC];\n        beta        = new double[nC];\n        permutation = new int[nC];\n        lmDir       = new double[nC];\n\n        \n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[nC];\n        double[] oldX    = new double[nC];\n        double[] oldRes  = new double[nR];\n        double[] oldObj  = new double[nR];\n        double[] qtf     = new double[nR];\n        double[] work1   = new double[nC];\n        double[] work2   = new double[nC];\n        double[] work3   = new double[nC];\n\n        final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n\n        \n        double[] currentObjective = computeObjectiveValue(currentPoint);\n        double[] currentResiduals = computeResiduals(currentObjective);\n        PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n        double currentCost = computeCost(currentResiduals);\n\n        \n        lmPar = 0;\n        boolean firstIteration = true;\n        final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n        while (true) {\n            incrementIterationCount();\n\n            final PointVectorValuePair previous = current;\n\n            \n            qrDecomposition(computeWeightedJacobian(currentPoint));\n\n            weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n            for (int i = 0; i < nR; i++) {\n                qtf[i] = weightedResidual[i];\n            }\n\n            \n            qTy(qtf);\n\n            \n            \n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                weightedJacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n                \n                \n                xNorm = 0;\n                for (int k = 0; k < nC; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * currentPoint[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = FastMath.sqrt(xNorm);\n\n                \n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n            }\n\n            \n            double maxCosine = 0;\n            if (currentCost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += weightedJacobian[i][pj] * qtf[i];\n                        }\n                        maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                \n                setCost(currentCost);\n                return current;\n            }\n\n            \n            for (int j = 0; j < nC; ++j) {\n                diag[j] = FastMath.max(diag[j], jacNorm[j]);\n            }\n\n            \n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                \n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = currentPoint[pj];\n                }\n                final double previousCost = currentCost;\n                double[] tmpVec = weightedResidual;\n                weightedResidual = oldRes;\n                oldRes    = tmpVec;\n                tmpVec    = currentObjective;\n                currentObjective = oldObj;\n                oldObj    = tmpVec;\n\n                \n                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n\n                \n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    currentPoint[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = FastMath.sqrt(lmNorm);\n                \n                if (firstIteration) {\n                    delta = FastMath.min(delta, lmNorm);\n                }\n\n                \n                currentObjective = computeObjectiveValue(currentPoint);\n                currentResiduals = computeResiduals(currentObjective);\n                current = new PointVectorValuePair(currentPoint, currentObjective);\n                currentCost = computeCost(currentResiduals);\n\n                \n                double actRed = -1.0;\n                if (0.1 * currentCost < previousCost) {\n                    double r = currentCost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                \n                \n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += weightedJacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                \n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                \n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                \n                if (ratio >= 1.0e-4) {\n                    \n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < nC; ++k) {\n                        double xK = diag[k] * currentPoint[k];\n                        xNorm += xK * xK;\n                    }\n                    xNorm = FastMath.sqrt(xNorm);\n\n                    \n                    if (checker != null) {\n                        \n                        if (checker.converged(getIterations(), previous, current)) {\n                            setCost(currentCost);\n                            return current;\n                        }\n                    }\n                } else {\n                    \n                    currentCost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        currentPoint[pj] = oldX[pj];\n                    }\n                    tmpVec    = weightedResidual;\n                    weightedResidual = oldRes;\n                    oldRes    = tmpVec;\n                    tmpVec    = currentObjective;\n                    currentObjective = oldObj;\n                    oldObj    = tmpVec;\n                    \n                    current = new PointVectorValuePair(currentPoint, currentObjective);\n                }\n\n                \n                if ((FastMath.abs(actRed) <= costRelativeTolerance &&\n                     preRed <= costRelativeTolerance &&\n                     ratio <= 2.0) ||\n                    delta <= parRelativeTolerance * xNorm) {\n                    setCost(currentCost);\n                    return current;\n                }\n\n                \n                \n                if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n                                                   costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n                                                   parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n                                                   orthoTolerance);\n                }\n            }\n        }\n    }\n\n    \n    private void determineLMParameter(double[] qy, double delta, double[] diag, double[] work1, double[] work2, double[] work3) {\n        final int nC = weightedJacobian[0].length;\n\n        \n        \n        for (int j = 0; j < rank; ++j) {\n            lmDir[permutation[j]] = qy[j];\n        }\n        for (int j = rank; j < nC; ++j) {\n            lmDir[permutation[j]] = 0;\n        }\n        for (int k = rank - 1; k >= 0; --k) {\n            int pk = permutation[k];\n            double ypk = lmDir[pk] / diagR[pk];\n            for (int i = 0; i < k; ++i) {\n                lmDir[permutation[i]] -= ypk * weightedJacobian[i][pk];\n            }\n            lmDir[pk] = ypk;\n        }\n\n        \n        \n        double dxNorm = 0;\n        for (int j = 0; j < solvedCols; ++j) {\n            int pj = permutation[j];\n            double s = diag[pj] * lmDir[pj];\n            work1[pj] = s;\n            dxNorm += s * s;\n        }\n        dxNorm = FastMath.sqrt(dxNorm);\n        double fp = dxNorm - delta;\n        if (fp <= 0.1 * delta) {\n            lmPar = 0;\n            return;\n        }\n\n        \n        \n        \n        double sum2;\n        double parl = 0;\n        if (rank == solvedCols) {\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] *= diag[pj] / dxNorm;\n            }\n            sum2 = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                double sum = 0;\n                for (int i = 0; i < j; ++i) {\n                    sum += weightedJacobian[i][pj] * work1[permutation[i]];\n                }\n                double s = (work1[pj] - sum) / diagR[pj];\n                work1[pj] = s;\n                sum2 += s * s;\n            }\n            parl = fp / (delta * sum2);\n        }\n\n        \n        sum2 = 0;\n        for (int j = 0; j < solvedCols; ++j) {\n            int pj = permutation[j];\n            double sum = 0;\n            for (int i = 0; i <= j; ++i) {\n                sum += weightedJacobian[i][pj] * qy[i];\n            }\n            sum /= diag[pj];\n            sum2 += sum * sum;\n        }\n        double gNorm = FastMath.sqrt(sum2);\n        double paru = gNorm / delta;\n        if (paru == 0) {\n            \n            paru = 2.2251e-308 / FastMath.min(delta, 0.1);\n        }\n\n        \n        \n        lmPar = FastMath.min(paru, FastMath.max(lmPar, parl));\n        if (lmPar == 0) {\n            lmPar = gNorm / dxNorm;\n        }\n\n        for (int countdown = 10; countdown >= 0; --countdown) {\n\n            \n            if (lmPar == 0) {\n                lmPar = FastMath.max(2.2251e-308, 0.001 * paru);\n            }\n            double sPar = FastMath.sqrt(lmPar);\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] = sPar * diag[pj];\n            }\n            determineLMDirection(qy, work1, work2, work3);\n\n            dxNorm = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                double s = diag[pj] * lmDir[pj];\n                work3[pj] = s;\n                dxNorm += s * s;\n            }\n            dxNorm = FastMath.sqrt(dxNorm);\n            double previousFP = fp;\n            fp = dxNorm - delta;\n\n            \n            \n            if ((FastMath.abs(fp) <= 0.1 * delta) ||\n                    ((parl == 0) && (fp <= previousFP) && (previousFP < 0))) {\n                return;\n            }\n\n            \n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] = work3[pj] * diag[pj] / dxNorm;\n            }\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                work1[pj] /= work2[j];\n                double tmp = work1[pj];\n                for (int i = j + 1; i < solvedCols; ++i) {\n                    work1[permutation[i]] -= weightedJacobian[i][pj] * tmp;\n                }\n            }\n            sum2 = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                double s = work1[permutation[j]];\n                sum2 += s * s;\n            }\n            double correction = fp / (delta * sum2);\n\n            \n            if (fp > 0) {\n                parl = FastMath.max(parl, lmPar);\n            } else if (fp < 0) {\n                paru = FastMath.min(paru, lmPar);\n            }\n\n            \n            lmPar = FastMath.max(parl, lmPar + correction);\n\n        }\n    }\n\n    \n    private void determineLMDirection(double[] qy, double[] diag, double[] lmDiag, double[] work) {\n\n        \n        \n        for (int j = 0; j < solvedCols; ++j) {\n            int pj = permutation[j];\n            for (int i = j + 1; i < solvedCols; ++i) {\n                weightedJacobian[i][pj] = weightedJacobian[j][permutation[i]];\n            }\n            lmDir[j] = diagR[pj];\n            work[j]  = qy[j];\n        }\n\n        \n        for (int j = 0; j < solvedCols; ++j) {\n\n            \n            \n            int pj = permutation[j];\n            double dpj = diag[pj];\n            if (dpj != 0) {\n                Arrays.fill(lmDiag, j + 1, lmDiag.length, 0);\n            }\n            lmDiag[j] = dpj;\n\n            \n            \n            \n            double qtbpj = 0;\n            for (int k = j; k < solvedCols; ++k) {\n                int pk = permutation[k];\n\n                \n                \n                if (lmDiag[k] != 0) {\n\n                    final double sin;\n                    final double cos;\n                    double rkk = weightedJacobian[k][pk];\n                    if (FastMath.abs(rkk) < FastMath.abs(lmDiag[k])) {\n                        final double cotan = rkk / lmDiag[k];\n                        sin   = 1.0 / FastMath.sqrt(1.0 + cotan * cotan);\n                        cos   = sin * cotan;\n                    } else {\n                        final double tan = lmDiag[k] / rkk;\n                        cos = 1.0 / FastMath.sqrt(1.0 + tan * tan);\n                        sin = cos * tan;\n                    }\n\n                    \n                    \n                    weightedJacobian[k][pk] = cos * rkk + sin * lmDiag[k];\n                    final double temp = cos * work[k] + sin * qtbpj;\n                    qtbpj = -sin * work[k] + cos * qtbpj;\n                    work[k] = temp;\n\n                    \n                    for (int i = k + 1; i < solvedCols; ++i) {\n                        double rik = weightedJacobian[i][pk];\n                        final double temp2 = cos * rik + sin * lmDiag[i];\n                        lmDiag[i] = -sin * rik + cos * lmDiag[i];\n                        weightedJacobian[i][pk] = temp2;\n                    }\n                }\n            }\n\n            \n            \n            lmDiag[j] = weightedJacobian[j][permutation[j]];\n            weightedJacobian[j][permutation[j]] = lmDir[j];\n        }\n\n        \n        \n        int nSing = solvedCols;\n        for (int j = 0; j < solvedCols; ++j) {\n            if ((lmDiag[j] == 0) && (nSing == solvedCols)) {\n                nSing = j;\n            }\n            if (nSing < solvedCols) {\n                work[j] = 0;\n            }\n        }\n        if (nSing > 0) {\n            for (int j = nSing - 1; j >= 0; --j) {\n                int pj = permutation[j];\n                double sum = 0;\n                for (int i = j + 1; i < nSing; ++i) {\n                    sum += weightedJacobian[i][pj] * work[i];\n                }\n                work[j] = (work[j] - sum) / lmDiag[j];\n            }\n        }\n\n        \n        for (int j = 0; j < lmDir.length; ++j) {\n            lmDir[permutation[j]] = work[j];\n        }\n    }\n\n    \n    private void qrDecomposition(RealMatrix jacobian) throws ConvergenceException {\n        \n        \n        weightedJacobian = jacobian.scalarMultiply(-1).getData();\n\n        final int nR = weightedJacobian.length;\n        final int nC = weightedJacobian[0].length;\n\n        \n        for (int k = 0; k < nC; ++k) {\n            permutation[k] = k;\n            double norm2 = 0;\n            for (int i = 0; i < nR; ++i) {\n                double akk = weightedJacobian[i][k];\n                norm2 += akk * akk;\n            }\n            jacNorm[k] = FastMath.sqrt(norm2);\n        }\n\n        \n        for (int k = 0; k < nC; ++k) {\n\n            \n            int nextColumn = -1;\n            double ak2 = Double.NEGATIVE_INFINITY;\n            for (int i = k; i < nC; ++i) {\n                double norm2 = 0;\n                for (int j = k; j < nR; ++j) {\n                    double aki = weightedJacobian[j][permutation[i]];\n                    norm2 += aki * aki;\n                }\n                if (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\n                    throw new ConvergenceException(LocalizedFormats.UNABLE_TO_PERFORM_QR_DECOMPOSITION_ON_JACOBIAN,\n                                                   nR, nC);\n                }\n                if (norm2 > ak2) {\n                    nextColumn = i;\n                    ak2        = norm2;\n                }\n            }\n            if (ak2 <= qrRankingThreshold) {\n                rank = k;\n                return;\n            }\n            int pk                  = permutation[nextColumn];\n            permutation[nextColumn] = permutation[k];\n            permutation[k]          = pk;\n\n            \n            double akk   = weightedJacobian[k][pk];\n            double alpha = (akk > 0) ? -FastMath.sqrt(ak2) : FastMath.sqrt(ak2);\n            double betak = 1.0 / (ak2 - akk * alpha);\n            beta[pk]     = betak;\n\n            \n            diagR[pk]        = alpha;\n            weightedJacobian[k][pk] -= alpha;\n\n            \n            for (int dk = nC - 1 - k; dk > 0; --dk) {\n                double gamma = 0;\n                for (int j = k; j < nR; ++j) {\n                    gamma += weightedJacobian[j][pk] * weightedJacobian[j][permutation[k + dk]];\n                }\n                gamma *= betak;\n                for (int j = k; j < nR; ++j) {\n                    weightedJacobian[j][permutation[k + dk]] -= gamma * weightedJacobian[j][pk];\n                }\n            }\n        }\n        rank = solvedCols;\n    }\n\n    \n    private void qTy(double[] y) {\n        final int nR = weightedJacobian.length;\n        final int nC = weightedJacobian[0].length;\n\n        for (int k = 0; k < nC; ++k) {\n            int pk = permutation[k];\n            double gamma = 0;\n            for (int i = k; i < nR; ++i) {\n                gamma += weightedJacobian[i][pk] * y[i];\n            }\n            gamma *= beta[pk];\n            for (int i = k; i < nR; ++i) {\n                y[i] -= gamma * weightedJacobian[i][pk];\n            }\n        }\n    }\n\n    \n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n",
      "buggy_signatures": [
        "public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer { private int solvedCols; private double[] diagR; private double[] jacNorm; private double[] beta; private int[] permutation; private int rank; private double lmPar; private double[] lmDir; private final double initialStepBoundFactor; private final double costRelativeTolerance; private final double parRelativeTolerance; private final double orthoTolerance; private final double qrRankingThreshold; private double[] weightedResidual; private double[][] weightedJacobian; public LevenbergMarquardtOptimizer()",
        "public LevenbergMarquardtOptimizer(ConvergenceChecker<PointVectorValuePair> checker)",
        "public LevenbergMarquardtOptimizer(double initialStepBoundFactor, ConvergenceChecker<PointVectorValuePair> checker, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold)",
        "public LevenbergMarquardtOptimizer(double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance)",
        "public LevenbergMarquardtOptimizer(double initialStepBoundFactor, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold)",
        "protected PointVectorValuePair doOptimize()",
        "private void determineLMParameter(double[] qy, double delta, double[] diag, double[] work1, double[] work2, double[] work3)",
        "private void determineLMDirection(double[] qy, double[] diag, double[] lmDiag, double[] work)",
        "private void qrDecomposition(RealMatrix jacobian) throws ConvergenceException",
        "private void qTy(double[] y)",
        "private void checkParameters()"
      ],
      "fixed_signatures": [
        "public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer { private int solvedCols; private double[] diagR; private double[] jacNorm; private double[] beta; private int[] permutation; private int rank; private double lmPar; private double[] lmDir; private final double initialStepBoundFactor; private final double costRelativeTolerance; private final double parRelativeTolerance; private final double orthoTolerance; private final double qrRankingThreshold; private double[] weightedResidual; private double[][] weightedJacobian; public LevenbergMarquardtOptimizer()",
        "public LevenbergMarquardtOptimizer(ConvergenceChecker<PointVectorValuePair> checker)",
        "public LevenbergMarquardtOptimizer(double initialStepBoundFactor, ConvergenceChecker<PointVectorValuePair> checker, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold)",
        "public LevenbergMarquardtOptimizer(double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance)",
        "public LevenbergMarquardtOptimizer(double initialStepBoundFactor, double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance, double threshold)",
        "protected PointVectorValuePair doOptimize()",
        "private void determineLMParameter(double[] qy, double delta, double[] diag, double[] work1, double[] work2, double[] work3)",
        "private void determineLMDirection(double[] qy, double[] diag, double[] lmDiag, double[] work)",
        "private void qrDecomposition(RealMatrix jacobian) throws ConvergenceException",
        "private void qTy(double[] y)",
        "private void checkParameters()"
      ],
      "methods": [
        {
          "buggy_method": "  protected PointVectorValuePair doOptimize() {\n  checkParameters();\n\n  final int nR = getTarget().length; \n  final double[] currentPoint = getStartPoint();\n  final int nC = currentPoint.length; \n\n  \n  solvedCols  = FastMath.min(nR, nC);\n  diagR  = new double[nC];\n  jacNorm  = new double[nC];\n  beta  = new double[nC];\n  permutation = new int[nC];\n  lmDir  = new double[nC];\n\n  \n  double  delta  = 0;\n  double  xNorm  = 0;\n  double[] diag  = new double[nC];\n  double[] oldX  = new double[nC];\n  double[] oldRes  = new double[nR];\n  double[] oldObj  = new double[nR];\n  double[] qtf  = new double[nR];\n  double[] work1  = new double[nC];\n  double[] work2  = new double[nC];\n  double[] work3  = new double[nC];\n\n  final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n\n  \n  double[] currentObjective = computeObjectiveValue(currentPoint);\n  double[] currentResiduals = computeResiduals(currentObjective);\n  PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n  double currentCost = computeCost(currentResiduals);\n\n  \n  lmPar = 0;\n  boolean firstIteration = true;\n  int iter = 0;\n  final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n  while (true) {\n  ++iter;\n  final PointVectorValuePair previous = current;\n\n  \n  qrDecomposition(computeWeightedJacobian(currentPoint));\n\n  weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n  for (int i = 0; i < nR; i++) {\n  qtf[i] = weightedResidual[i];\n  }\n\n  \n  qTy(qtf);\n\n  \n  \n  for (int k = 0; k < solvedCols; ++k) {\n  int pk = permutation[k];\n  weightedJacobian[k][pk] = diagR[pk];\n  }\n\n  if (firstIteration) {\n  \n  \n  xNorm = 0;\n  for (int k = 0; k < nC; ++k) {\n  double dk = jacNorm[k];\n  if (dk == 0) {\n  dk = 1.0;\n  }\n  double xk = dk * currentPoint[k];\n  xNorm  += xk * xk;\n  diag[k] = dk;\n  }\n  xNorm = FastMath.sqrt(xNorm);\n\n  \n  delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n  }\n\n  \n  double maxCosine = 0;\n  if (currentCost != 0) {\n  for (int j = 0; j < solvedCols; ++j) {\n  int  pj = permutation[j];\n  double s  = jacNorm[pj];\n  if (s != 0) {\n  double sum = 0;\n  for (int i = 0; i <= j; ++i) {\n  sum += weightedJacobian[i][pj] * qtf[i];\n  }\n  maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n  }\n  }\n  }\n  if (maxCosine <= orthoTolerance) {\n  \n  setCost(currentCost);\n  return current;\n  }\n\n  \n  for (int j = 0; j < nC; ++j) {\n  diag[j] = FastMath.max(diag[j], jacNorm[j]);\n  }\n\n  \n  for (double ratio = 0; ratio < 1.0e-4;) {\n\n  \n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  oldX[pj] = currentPoint[pj];\n  }\n  final double previousCost = currentCost;\n  double[] tmpVec = weightedResidual;\n  weightedResidual = oldRes;\n  oldRes  = tmpVec;\n  tmpVec  = currentObjective;\n  currentObjective = oldObj;\n  oldObj  = tmpVec;\n\n  \n  determineLMParameter(qtf, delta, diag, work1, work2, work3);\n\n  \n  double lmNorm = 0;\n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  lmDir[pj] = -lmDir[pj];\n  currentPoint[pj] = oldX[pj] + lmDir[pj];\n  double s = diag[pj] * lmDir[pj];\n  lmNorm  += s * s;\n  }\n  lmNorm = FastMath.sqrt(lmNorm);\n  \n  if (firstIteration) {\n  delta = FastMath.min(delta, lmNorm);\n  }\n\n  \n  currentObjective = computeObjectiveValue(currentPoint);\n  currentResiduals = computeResiduals(currentObjective);\n  current = new PointVectorValuePair(currentPoint, currentObjective);\n  currentCost = computeCost(currentResiduals);\n\n  \n  double actRed = -1.0;\n  if (0.1 * currentCost < previousCost) {\n  double r = currentCost / previousCost;\n  actRed = 1.0 - r * r;\n  }\n\n  \n  \n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  double dirJ = lmDir[pj];\n  work1[j] = 0;\n  for (int i = 0; i <= j; ++i) {\n  work1[i] += weightedJacobian[i][pj] * dirJ;\n  }\n  }\n  double coeff1 = 0;\n  for (int j = 0; j < solvedCols; ++j) {\n  coeff1 += work1[j] * work1[j];\n  }\n  double pc2 = previousCost * previousCost;\n  coeff1 = coeff1 / pc2;\n  double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n  double preRed = coeff1 + 2 * coeff2;\n  double dirDer = -(coeff1 + coeff2);\n\n  \n  ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n  \n  if (ratio <= 0.25) {\n  double tmp =\n  (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n  if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n  tmp = 0.1;\n  }\n  delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n  lmPar /= tmp;\n  } else if ((lmPar == 0) || (ratio >= 0.75)) {\n  delta = 2 * lmNorm;\n  lmPar *= 0.5;\n  }\n\n  \n  if (ratio >= 1.0e-4) {\n  \n  firstIteration = false;\n  xNorm = 0;\n  for (int k = 0; k < nC; ++k) {\n  double xK = diag[k] * currentPoint[k];\n  xNorm += xK * xK;\n  }\n  xNorm = FastMath.sqrt(xNorm);\n\n  \n  if (checker != null) {\n  \n  if (checker.converged(iter, previous, current)) {\n  setCost(currentCost);\n  return current;\n  }\n  }\n  } else {\n  \n  currentCost = previousCost;\n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  currentPoint[pj] = oldX[pj];\n  }\n  tmpVec  = weightedResidual;\n  weightedResidual = oldRes;\n  oldRes  = tmpVec;\n  tmpVec  = currentObjective;\n  currentObjective = oldObj;\n  oldObj  = tmpVec;\n  \n  current = new PointVectorValuePair(currentPoint, currentObjective);\n  }\n\n  \n  if ((FastMath.abs(actRed) <= costRelativeTolerance &&\n  preRed <= costRelativeTolerance &&\n  ratio <= 2.0) ||\n  delta <= parRelativeTolerance * xNorm) {\n  setCost(currentCost);\n  return current;\n  }\n\n  \n  \n  if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n  throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n  costRelativeTolerance);\n  } else if (delta <= 2.2204e-16 * xNorm) {\n  throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n  parRelativeTolerance);\n  } else if (maxCosine <= 2.2204e-16)  {\n  throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n  orthoTolerance);\n  }\n  }\n  }\n  }",
          "fixed_method": "  protected PointVectorValuePair doOptimize() {\n  checkParameters();\n\n  final int nR = getTarget().length; \n  final double[] currentPoint = getStartPoint();\n  final int nC = currentPoint.length; \n\n  \n  solvedCols  = FastMath.min(nR, nC);\n  diagR  = new double[nC];\n  jacNorm  = new double[nC];\n  beta  = new double[nC];\n  permutation = new int[nC];\n  lmDir  = new double[nC];\n\n  \n  double  delta  = 0;\n  double  xNorm  = 0;\n  double[] diag  = new double[nC];\n  double[] oldX  = new double[nC];\n  double[] oldRes  = new double[nR];\n  double[] oldObj  = new double[nR];\n  double[] qtf  = new double[nR];\n  double[] work1  = new double[nC];\n  double[] work2  = new double[nC];\n  double[] work3  = new double[nC];\n\n  final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n\n  \n  double[] currentObjective = computeObjectiveValue(currentPoint);\n  double[] currentResiduals = computeResiduals(currentObjective);\n  PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n  double currentCost = computeCost(currentResiduals);\n\n  \n  lmPar = 0;\n  boolean firstIteration = true;\n  final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n  while (true) {\n  incrementIterationCount();\n\n  final PointVectorValuePair previous = current;\n\n  \n  qrDecomposition(computeWeightedJacobian(currentPoint));\n\n  weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n  for (int i = 0; i < nR; i++) {\n  qtf[i] = weightedResidual[i];\n  }\n\n  \n  qTy(qtf);\n\n  \n  \n  for (int k = 0; k < solvedCols; ++k) {\n  int pk = permutation[k];\n  weightedJacobian[k][pk] = diagR[pk];\n  }\n\n  if (firstIteration) {\n  \n  \n  xNorm = 0;\n  for (int k = 0; k < nC; ++k) {\n  double dk = jacNorm[k];\n  if (dk == 0) {\n  dk = 1.0;\n  }\n  double xk = dk * currentPoint[k];\n  xNorm  += xk * xk;\n  diag[k] = dk;\n  }\n  xNorm = FastMath.sqrt(xNorm);\n\n  \n  delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n  }\n\n  \n  double maxCosine = 0;\n  if (currentCost != 0) {\n  for (int j = 0; j < solvedCols; ++j) {\n  int  pj = permutation[j];\n  double s  = jacNorm[pj];\n  if (s != 0) {\n  double sum = 0;\n  for (int i = 0; i <= j; ++i) {\n  sum += weightedJacobian[i][pj] * qtf[i];\n  }\n  maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n  }\n  }\n  }\n  if (maxCosine <= orthoTolerance) {\n  \n  setCost(currentCost);\n  return current;\n  }\n\n  \n  for (int j = 0; j < nC; ++j) {\n  diag[j] = FastMath.max(diag[j], jacNorm[j]);\n  }\n\n  \n  for (double ratio = 0; ratio < 1.0e-4;) {\n\n  \n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  oldX[pj] = currentPoint[pj];\n  }\n  final double previousCost = currentCost;\n  double[] tmpVec = weightedResidual;\n  weightedResidual = oldRes;\n  oldRes  = tmpVec;\n  tmpVec  = currentObjective;\n  currentObjective = oldObj;\n  oldObj  = tmpVec;\n\n  \n  determineLMParameter(qtf, delta, diag, work1, work2, work3);\n\n  \n  double lmNorm = 0;\n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  lmDir[pj] = -lmDir[pj];\n  currentPoint[pj] = oldX[pj] + lmDir[pj];\n  double s = diag[pj] * lmDir[pj];\n  lmNorm  += s * s;\n  }\n  lmNorm = FastMath.sqrt(lmNorm);\n  \n  if (firstIteration) {\n  delta = FastMath.min(delta, lmNorm);\n  }\n\n  \n  currentObjective = computeObjectiveValue(currentPoint);\n  currentResiduals = computeResiduals(currentObjective);\n  current = new PointVectorValuePair(currentPoint, currentObjective);\n  currentCost = computeCost(currentResiduals);\n\n  \n  double actRed = -1.0;\n  if (0.1 * currentCost < previousCost) {\n  double r = currentCost / previousCost;\n  actRed = 1.0 - r * r;\n  }\n\n  \n  \n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  double dirJ = lmDir[pj];\n  work1[j] = 0;\n  for (int i = 0; i <= j; ++i) {\n  work1[i] += weightedJacobian[i][pj] * dirJ;\n  }\n  }\n  double coeff1 = 0;\n  for (int j = 0; j < solvedCols; ++j) {\n  coeff1 += work1[j] * work1[j];\n  }\n  double pc2 = previousCost * previousCost;\n  coeff1 = coeff1 / pc2;\n  double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n  double preRed = coeff1 + 2 * coeff2;\n  double dirDer = -(coeff1 + coeff2);\n\n  \n  ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n  \n  if (ratio <= 0.25) {\n  double tmp =\n  (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n  if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n  tmp = 0.1;\n  }\n  delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n  lmPar /= tmp;\n  } else if ((lmPar == 0) || (ratio >= 0.75)) {\n  delta = 2 * lmNorm;\n  lmPar *= 0.5;\n  }\n\n  \n  if (ratio >= 1.0e-4) {\n  \n  firstIteration = false;\n  xNorm = 0;\n  for (int k = 0; k < nC; ++k) {\n  double xK = diag[k] * currentPoint[k];\n  xNorm += xK * xK;\n  }\n  xNorm = FastMath.sqrt(xNorm);\n\n  \n  if (checker != null) {\n  \n  if (checker.converged(getIterations(), previous, current)) {\n  setCost(currentCost);\n  return current;\n  }\n  }\n  } else {\n  \n  currentCost = previousCost;\n  for (int j = 0; j < solvedCols; ++j) {\n  int pj = permutation[j];\n  currentPoint[pj] = oldX[pj];\n  }\n  tmpVec  = weightedResidual;\n  weightedResidual = oldRes;\n  oldRes  = tmpVec;\n  tmpVec  = currentObjective;\n  currentObjective = oldObj;\n  oldObj  = tmpVec;\n  \n  current = new PointVectorValuePair(currentPoint, currentObjective);\n  }\n\n  \n  if ((FastMath.abs(actRed) <= costRelativeTolerance &&\n  preRed <= costRelativeTolerance &&\n  ratio <= 2.0) ||\n  delta <= parRelativeTolerance * xNorm) {\n  setCost(currentCost);\n  return current;\n  }\n\n  \n  \n  if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n  throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n  costRelativeTolerance);\n  } else if (delta <= 2.2204e-16 * xNorm) {\n  throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n  parRelativeTolerance);\n  } else if (maxCosine <= 2.2204e-16)  {\n  throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n  orthoTolerance);\n  }\n  }\n  }\n  }",
          "diff": [
            "@@ -319,10 +319,10 @@",
            "         // Outer loop.\n",
            "         lmPar = 0;\n",
            "         boolean firstIteration = true;\n",
            "-        int iter = 0;\n",
            "         final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n",
            "         while (true) {\n",
            "-            ++iter;\n",
            "+            incrementIterationCount();\n",
            "+\n",
            "             final PointVectorValuePair previous = current;\n",
            " \n",
            "             // QR decomposition of the jacobian matrix\n",
            "@@ -486,7 +486,7 @@",
            "                     // tests for convergence.\n",
            "                     if (checker != null) {\n",
            "                         // we use the vectorial convergence checker\n",
            "-                        if (checker.converged(iter, previous, current)) {\n",
            "+                        if (checker.converged(getIterations(), previous, current)) {\n",
            "                             setCost(currentCost);\n",
            "                             return current;\n",
            "                         }\n"
          ],
          "changed_lines": 6
        }
      ]
    }
  ]
}
